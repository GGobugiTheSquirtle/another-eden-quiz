#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ”§ Another Eden ë§ˆìŠ¤í„° ìŠ¤í¬ë˜í¼
ìŠ¤í¬ë˜í•‘ â†’ ì´ë¯¸ì§€ ì •ë¦¬ â†’ CSV ìƒì„± â†’ ë°ì´í„° ì •ë¦¬ê¹Œì§€ ëª¨ë“  ì‘ì—…ì„ í†µí•© ì²˜ë¦¬
"""

import os
import sys
import time
import requests
import pandas as pd
from pathlib import Path
from bs4 import BeautifulSoup
from urllib.parse import urljoin, unquote, parse_qs, urlparse
import re
import unicodedata
import mimetypes
import base64
from openpyxl import Workbook
from openpyxl.drawing.image import Image as OpenpyxlImage
import shutil

# ë ˆê±°ì‹œ ë°©ì‹ ë§¤í•‘ í…Œì´ë¸” ì¶”ê°€
ELEMENT_MAPPING = {
    # ì†ì„± ì•„ì´ì½˜ ë§¤í•‘ (ì‹¤ì œ íŒŒì¼ëª… â†’ í•œê¸€ ì†ì„±ëª…)
    "Skill_Type_8_0.png": "ë¬´ì†ì„±",
    "Skill_Type_8_1.png": "ë¶ˆ",
    "Skill_Type_8_2.png": "ë•…",
    "Skill_Type_8_4.png": "ë¬¼", 
    "Skill_Type_8_8.png": "ë°”ëŒ",
    "Skill_Type_8_16.png": "ë²ˆê°œ",
    "Skill_Type_8_32.png": "ê·¸ë¦¼ì",
    "Skill_Type_8_64.png": "ìˆ˜ì •",
    # ì¶”ê°€ íŒ¨í„´ë“¤
    "St_attack_element_change1.png": "ë¶ˆ",
    "St_attack_element_change2.png": "ë•…", 
    "St_attack_element_change4.png": "ë¬¼",
    "St_attack_element_change8.png": "ë°”ëŒ",
    "St_attack_element_change16.png": "ë²ˆê°œ",
    "St_attack_element_change32.png": "ê·¸ë¦¼ì",
    "St_attack_element_change64.png": "ìˆ˜ì •",
    # Light/Shadow ì•„ì´ì½˜ë“¤
    "Guiding_Light_Icon.png": "ë¹›",
    "Luring_Shadow_Icon.png": "ê·¸ë¦¼ì",
}

# ALT í…ìŠ¤íŠ¸ ê¸°ë°˜ ë§¤í•‘ ì¶”ê°€
ALT_TEXT_MAPPING = {
    # ALT í…ìŠ¤íŠ¸ â†’ ë¶„ë¥˜ ë° í•œê¸€ëª…
    "Luring Shadow Icon.png": ("element", "ê·¸ë¦¼ì"),
    "Guiding Light Icon.png": ("element", "ë¹›"),
    "Skill Type 8 0.png": ("element", "ë¬´ì†ì„±"),
    "Skill Type 8 1.png": ("element", "ë¶ˆ"),
    "Skill Type 8 2.png": ("element", "ë•…"),
    "Skill Type 8 4.png": ("element", "ë¬¼"),
    "Skill Type 8 8.png": ("element", "ë°”ëŒ"),
    "Skill Type 8 16.png": ("element", "ë²ˆê°œ"),
    "Skill Type 8 32.png": ("element", "ê·¸ë¦¼ì"),
    "Skill Type 8 64.png": ("element", "ìˆ˜ì •"),
    # ë¬´ê¸° ALT í…ìŠ¤íŠ¸ë“¤ (ì˜ˆì‹œ - ì‹¤ì œ ì›¹ì—ì„œ í™•ì¸ í›„ ì—…ë°ì´íŠ¸)
    "202000000 icon.png": ("weapon", "ì§€íŒ¡ì´"),
    "202000001 icon.png": ("weapon", "ê²€"),
    "202000002 icon.png": ("weapon", "ë„"),
    "202000003 icon.png": ("weapon", "ë„ë¼"),
    "202000004 icon.png": ("weapon", "ì°½"),
    "202000005 icon.png": ("weapon", "í™œ"),
    "202000006 icon.png": ("weapon", "ì£¼ë¨¹"),
    "202000007 icon.png": ("weapon", "ë§ì¹˜"),
}

WEAPON_MAPPING = {
    # ë¬´ê¸° ì•„ì´ì½˜ ë§¤í•‘ (ì‹¤ì œ íŒŒì¼ëª… â†’ í•œê¸€ ë¬´ê¸°ëª…)
    "202000000_icon.png": "ì§€íŒ¡ì´",
    "202000001_icon.png": "ê²€",
    "202000002_icon.png": "ë„",
    "202000003_icon.png": "ë„ë¼",
    "202000004_icon.png": "ì°½",
    "202000005_icon.png": "í™œ",
    "202000006_icon.png": "ì£¼ë¨¹",
    "202000007_icon.png": "ë§ì¹˜",
}

ARMOR_MAPPING = {
    # ë°©ì–´êµ¬ ì•„ì´ì½˜ ë§¤í•‘
    "216000002_icon.png": "íŒ”ì°Œ",
    "216000003_icon.png": "ëª©ê±¸ì´", 
    "216000004_icon.png": "ë°˜ì§€",
}

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent.resolve()
SCRAPING_DIR = PROJECT_ROOT / "01_scraping"
DATA_DIR = PROJECT_ROOT / "04_data"
CSV_DIR = DATA_DIR / "csv"
IMAGE_DIR = DATA_DIR / "images" / "character_art"

# ìŠ¤í¬ë˜í•‘ ì„¤ì •
BASE_URL = "https://anothereden.wiki"
TARGET_URL = "https://anothereden.wiki/w/Characters"
PERSONALITY_URL = "https://anothereden.wiki/w/Characters/Personality"


class MasterScraper:
    """í†µí•© ë§ˆìŠ¤í„° ìŠ¤í¬ë˜í¼"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent.resolve()
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        self.character_data = []
        self.name_mapping = {}
        self.personality_mapping = {}
        self.setup_directories()
        
    def setup_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        for directory in [CSV_DIR, IMAGE_DIR]:
            directory.mkdir(parents=True, exist_ok=True)
        
        # ì´ë¯¸ì§€ í•˜ìœ„ í´ë”
        (IMAGE_DIR / "icons").mkdir(exist_ok=True)
        (IMAGE_DIR / "elements_equipment").mkdir(exist_ok=True)
        
        print(f"âœ… ë””ë ‰í† ë¦¬ ì„¤ì • ì™„ë£Œ")
        print(f"   ğŸ“Š ë°ì´í„°: {CSV_DIR}")
        print(f"   ğŸ–¼ï¸ ì´ë¯¸ì§€: {IMAGE_DIR}")
    
    def load_name_mapping(self):
        """í•œê¸€ ì´ë¦„ ë§¤í•‘ ë¡œë“œ"""
        mapping_file = CSV_DIR / "Matching_names.csv"
        if mapping_file.exists():
            try:
                df = pd.read_csv(mapping_file, encoding='utf-8-sig')
                for _, row in df.iterrows():
                    if len(row) >= 2:
                        eng_name = str(row.iloc[0]).strip()
                        kor_name = str(row.iloc[1]).strip()
                        if eng_name and kor_name and kor_name != 'nan':
                            self.name_mapping[eng_name.lower()] = kor_name
                print(f"âœ… í•œê¸€ ë§¤ì¹­ ë¡œë“œ: {len(self.name_mapping)}ê°œ")
            except Exception as e:
                print(f"âš ï¸ ë§¤í•‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
        else:
            print("âš ï¸ Matching_names.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    def load_personality_mapping(self):
        """í¼ìŠ¤ë„ë¦¬í‹° ë§¤í•‘ ë¡œë“œ"""
        mapping_file = CSV_DIR / "personality_matching.csv"
        if mapping_file.exists():
            try:
                df = pd.read_csv(mapping_file)
                for _, row in df.iterrows():
                    if 'English' in row and 'Korean' in row:
                        self.personality_mapping[row['English']] = row['Korean']
                print(f"âœ… í¼ìŠ¤ë„ë¦¬í‹° ë§¤í•‘ ë¡œë“œ: {len(self.personality_mapping)}ê°œ")
            except Exception as e:
                print(f"âš ï¸ í¼ìŠ¤ë„ë¦¬í‹° ë§¤í•‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
        else:
            print("âš ï¸ personality_matching.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    def convert_to_korean(self, english_name):
        """ì˜ì–´ ì´ë¦„ì„ í•œê¸€ë¡œ ë³€í™˜ (ìŠ¤íƒ€ì¼ ì ‘ë¯¸ì‚¬ ê³ ë ¤)"""
        if not english_name:
            return english_name

        # ìŠ¤íƒ€ì¼ê³¼ ì¶•ì•½í˜• ë§¤í•‘
        style_map = {
            'Another Style': 'AS',
            'Extra Style': 'ES',
            'AS': 'AS',
            'ES': 'ES',
            'Alter': 'Alter',
            'Manifestation': 'M',
            'NS': 'NS'
        }

        base_name = english_name.strip()
        style_suffix = ""

        # ì •ê·œì‹ íŒ¨í„´ ìƒì„±
        pattern_str = r'\s*\(?(' + '|'.join(re.escape(k) for k in style_map.keys()) + r')\)?$'
        
        match = re.search(pattern_str, base_name, re.IGNORECASE)
        
        if match:
            matched_style_key = match.group(1)
            for key, abbreviation in style_map.items():
                if key.lower() == matched_style_key.lower():
                    style_suffix = " " + abbreviation
                    break
            
            base_name = base_name[:match.start()].strip()

        # ê¸°ë³¸ ì´ë¦„ì„ í•œê¸€ë¡œ ë³€í™˜
        korean_base = self.name_mapping.get(base_name.lower(), base_name)
        
        return korean_base + style_suffix
    
    def sanitize_filename(self, name):
        """íŒŒì¼ëª…ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜"""
        name = unicodedata.normalize('NFKC', name)
        name = re.sub(r'[<>:"/\\|?*]', '_', name)
        name = name.strip()
        return name
    
    def normalize_image_filename(self, korean_name, english_name):
        """ì´ë¯¸ì§€ íŒŒì¼ëª… ì •ê·œí™”"""
        # í•œê¸€ ì´ë¦„ì„ ìš°ì„  ì‚¬ìš©í•˜ë˜, íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬
        if korean_name and korean_name.strip():
            base_name = korean_name.strip()
        else:
            base_name = english_name.strip()
        
        # íŒŒì¼ëª… ì •ê·œí™”
        normalized = self.sanitize_filename(base_name)
        return f"{normalized}.png"
    
    def get_unique_filename(self, filepath):
        """ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ê³ ìœ  íŒŒì¼ëª… ìƒì„±"""
        if not os.path.exists(filepath):
            return filepath
        base, ext = os.path.splitext(filepath)
        counter = 1
        while True:
            new_filepath = f"{base} ({counter}){ext}"
            if not os.path.exists(new_filepath):
                return new_filepath
            counter += 1
    
    def download_image(self, image_url, kor_name="", eng_name=""):
        """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
        if not image_url:
            return None

        full_image_url = urljoin(BASE_URL, image_url)
        try:
            # íŒŒì¼ ì´ë¦„ ë° í™•ì¥ì ê²°ì •
            parsed_url = urlparse(full_image_url)
            query_params = parse_qs(parsed_url.query)
            image_name_from_f = query_params.get('f', [None])[0]

            if image_name_from_f:
                image_name = os.path.basename(unquote(image_name_from_f))
            else:
                image_name = os.path.basename(unquote(parsed_url.path.split('?')[0]))

            if not image_name or image_name.lower() in ["thumb.php", "index.php"]:
                image_name = (eng_name or kor_name or "unknown") + ".png"

            base_name, ext = os.path.splitext(image_name)
            if not ext or len(ext) > 5:
                try:
                    head_resp = requests.head(full_image_url, timeout=5, allow_redirects=True)
                    head_resp.raise_for_status()
                    content_type = head_resp.headers.get('Content-Type')
                    if content_type:
                        guessed_ext = mimetypes.guess_extension(content_type.split(';')[0])
                        ext = guessed_ext if guessed_ext and guessed_ext != '.jpe' else ('.jpg' if guessed_ext == '.jpe' else '.png')
                    else:
                        ext = ".png"
                except requests.exceptions.RequestException:
                    ext = ".png"

            # ìµœì¢… íŒŒì¼ ì´ë¦„ ìƒì„± (ì •ê·œí™”ëœ í•œê¸€ëª… ìš°ì„ )
            final_name = self.normalize_image_filename(kor_name, eng_name)
            final_filename = final_name

            # ì €ì¥ ê²½ë¡œ ì„¤ì • ë° ì¤‘ë³µ í™•ì¸
            save_path = IMAGE_DIR / final_filename
            save_path.parent.mkdir(parents=True, exist_ok=True)

            if save_path.exists() and save_path.stat().st_size > 0:
                return str(save_path.relative_to(self.project_root).as_posix())

            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            img_response = requests.get(full_image_url, headers=self.headers, timeout=20, stream=True)
            img_response.raise_for_status()

            with open(save_path, 'wb') as f:
                for chunk in img_response.iter_content(8192):
                    f.write(chunk)
            
            return str(save_path.relative_to(self.project_root).as_posix())

        except requests.exceptions.RequestException as e:
            print(f"âš ï¸ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ë¡œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {full_image_url} ({e})")
            return None
        except Exception as e:
            print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ë¡œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {full_image_url} ({e})")
            return None
    
    def download_character_image(self, image_url, kor_name, eng_name):
        """ìºë¦­í„° ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥ (ì¤‘ë³µ ë°©ì§€ ê°œì„ )"""
        if not image_url:
            return None
        
        try:
            # URL ì •ê·œí™”
            if not image_url.startswith('http'):
                full_image_url = urljoin(BASE_URL, image_url)
            else:
                full_image_url = image_url
            
            # íŒŒì¼ëª… ì •ê·œí™”
            final_name = self.normalize_image_filename(kor_name, eng_name)
            final_filename = final_name

            # ì €ì¥ ê²½ë¡œ ì„¤ì • ë° ì¤‘ë³µ í™•ì¸
            save_path = IMAGE_DIR / final_filename
            save_path.parent.mkdir(parents=True, exist_ok=True)

            # ì¤‘ë³µ íŒŒì¼ ì²´í¬ ê°•í™” (íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ê³  í¬ê¸°ê°€ ì ì ˆí•˜ë©´ ìŠ¤í‚µ)
            if save_path.exists() and save_path.stat().st_size > 1000:  # ìµœì†Œ 1KB
                print(f"  âœ… ì´ë¯¸ì§€ ì´ë¯¸ ì¡´ì¬: {save_path.name}")
                return str(save_path.relative_to(self.project_root).as_posix())

            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            print(f"  ğŸ“¥ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘: {save_path.name}")
            img_response = requests.get(full_image_url, headers=self.headers, timeout=20, stream=True)
            img_response.raise_for_status()

            # íŒŒì¼ í¬ê¸° ì²´í¬
            content_length = img_response.headers.get('content-length')
            if content_length and int(content_length) < 1000:
                print(f"  âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŒ: {content_length}ë°”ì´íŠ¸")
                return None

            # íŒŒì¼ ì €ì¥
            with open(save_path, 'wb') as f:
                for chunk in img_response.iter_content(8192):
                    f.write(chunk)
            
            # ì €ì¥ëœ íŒŒì¼ í¬ê¸° ì¬í™•ì¸
            if save_path.stat().st_size < 1000:
                print(f"  âš ï¸ ì €ì¥ëœ ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŒ")
                save_path.unlink()  # ì‘ì€ íŒŒì¼ ì‚­ì œ
                return None
            
            print(f"  âœ… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {save_path.name} ({save_path.stat().st_size}ë°”ì´íŠ¸)")
            return str(save_path.relative_to(self.project_root).as_posix())

        except requests.exceptions.RequestException as e:
            print(f"  âš ï¸ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ë¡œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {full_image_url} ({e})")
            return None
        except Exception as e:
            print(f"  âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ë¡œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {full_image_url} ({e})")
            return None
    
    def download_icon(self, icon_url, alt_text, subfolder):
        """ì•„ì´ì½˜ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥ (ì¤‘ë³µ ë°©ì§€)"""
        if not icon_url:
            return ""
        
        try:
            # URL ì •ê·œí™”
            if not icon_url.startswith('http'):
                icon_url = urljoin(BASE_URL, icon_url)
            
            # alt_text ì•ˆì „ ì²˜ë¦¬
            if alt_text is None:
                alt_text = "unknown"
            elif not isinstance(alt_text, str):
                try:
                    alt_text = str(alt_text)
                except:
                    alt_text = "unknown"
            
            # URLì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
            parsed_url = urlparse(icon_url)
            query_params = parse_qs(parsed_url.query)
            icon_name_from_f = query_params.get('f', [None])[0]
            
            # ì›ë³¸ íŒŒì¼ëª… ê¸°ë°˜ìœ¼ë¡œ ì €ì¥ íŒŒì¼ëª… ìƒì„±
            if icon_name_from_f:
                original_name = os.path.basename(unquote(icon_name_from_f))
                base_name, ext = os.path.splitext(original_name)
            else:
                original_name = os.path.basename(unquote(parsed_url.path.split('?')[0]))
                base_name, ext = os.path.splitext(original_name)
            
            # í™•ì¥ì ì²˜ë¦¬
            if not ext or ext.lower() in ['.php'] or len(ext) > 5:
                ext = ".png"
            
            # íŒŒì¼ëª… ì •ë¦¬ (ì›ë³¸ íŒŒì¼ëª… ìš°ì„  ì‚¬ìš©)
            if base_name and base_name.lower() not in ["thumb", "index"]:
                clean_name = self.sanitize_filename(base_name)
            else:
                # alt_textë¥¼ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©
                clean_name = re.sub(r'[^\w\-_]', '', alt_text.replace(' ', '_').lower())
                if not clean_name:
                    clean_name = "unknown"
            
            icon_filename = f"{clean_name}{ext}"
            
            # ì €ì¥ ê²½ë¡œ ì„¤ì •
            icon_dir = IMAGE_DIR / subfolder
            icon_dir.mkdir(exist_ok=True)
            save_path = icon_dir / icon_filename
            
            # ì¤‘ë³µ íŒŒì¼ ì²´í¬ (íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ê³  í¬ê¸°ê°€ 0ë³´ë‹¤ í¬ë©´ ìŠ¤í‚µ)
            if save_path.exists() and save_path.stat().st_size > 0:
                return str(save_path.relative_to(self.project_root).as_posix())
            
            # ì¤‘ë³µ íŒŒì¼ëª… ì²˜ë¦¬ (í•„ìš”ì‹œ)
            save_path = self.get_unique_filename(save_path)
            
            # ì•„ì´ì½˜ ë‹¤ìš´ë¡œë“œ
            response = requests.get(icon_url, headers=self.headers, timeout=30)
            response.raise_for_status()
            
            # íŒŒì¼ í¬ê¸° ì²´í¬ (ìµœì†Œ 100ë°”ì´íŠ¸)
            if len(response.content) < 100:
                print(f"  âš ï¸ íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŒ: {icon_url}")
                return ""
            
            # íŒŒì¼ ì €ì¥
            with open(save_path, 'wb') as f:
                f.write(response.content)
            
            print(f"  ğŸ¯ ì•„ì´ì½˜ ì €ì¥: {save_path.name}")
            return str(save_path.relative_to(self.project_root).as_posix())
            
        except requests.exceptions.RequestException as e:
            print(f"  âš ï¸ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ë¡œ ì•„ì´ì½˜ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({icon_url}): {e}")
            return ""
        except Exception as e:
            print(f"  âš ï¸ ì•„ì´ì½˜ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({icon_url}): {e}")
            return ""
    
    def scrape_character_list(self):
        """ìºë¦­í„° ëª©ë¡ í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ (ì¶œì‹œì¼ í¬í•¨)"""
        print("ğŸ“¡ ìºë¦­í„° ëª©ë¡ ìŠ¤í¬ë˜í•‘ ì¤‘...")
        try:
            response = requests.get(TARGET_URL, headers=self.headers, timeout=30)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ìºë¦­í„° í…Œì´ë¸” ì°¾ê¸° (ë‹¤ì–‘í•œ í´ë˜ìŠ¤ëª… ì‹œë„)
            char_table = soup.find('table', class_='chara-table') or soup.find('table', class_='wikitable')
            if not char_table:
                print("âŒ ìºë¦­í„° í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            characters = []
            rows = char_table.find_all('tr')[1:]  # í—¤ë” ì œì™¸
            
            for row in rows:
                cols = row.find_all(['td', 'th'])
                if len(cols) < 4:  # ìµœì†Œ 4ê°œ ì»¬ëŸ¼ í•„ìš” (ì•„ì´ì½˜, ì´ë¦„, ì†ì„±/ì¥ë¹„, ì¶œì‹œì¼)
                    continue
                
                try:
                    # ìºë¦­í„° ë§í¬ ë° ì´ë¦„ ì¶”ì¶œ
                    char_link = cols[1].find('a')  # ì´ë¦„ì€ ë³´í†µ ë‘ ë²ˆì§¸ ì»¬ëŸ¼
                    if not char_link:
                        continue
                    
                    eng_name = char_link.get('title', '').strip()
                    detail_url = urljoin(BASE_URL, char_link.get('href', ''))
                    
                    if not eng_name or not detail_url:
                        continue
                    
                    # ì´ë¯¸ì§€ URL ì¶”ì¶œ (ì²« ë²ˆì§¸ ì»¬ëŸ¼)
                    img_tag = cols[0].find('img')
                    img_url = img_tag.get('src', '') if img_tag else ''
                    
                    # ì¶œì‹œì¼ ì¶”ì¶œ (ë„¤ ë²ˆì§¸ ì»¬ëŸ¼, ë ˆê±°ì‹œ ë¡œì§ ì ìš©)
                    release_date = ""
                    if len(cols) >= 4:
                        release_date = cols[3].get_text(strip=True)
                        # ë‚ ì§œ í˜•ì‹ ì •ê·œí™” (YYYY/MM/DD)
                        if release_date and len(release_date) > 5:
                            # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì²˜ë¦¬
                            date_match = re.search(r'(\d{4})[/-](\d{1,2})[/-](\d{1,2})', release_date)
                            if date_match:
                                year, month, day = date_match.groups()
                                release_date = f"{year}/{int(month):02d}/{int(day):02d}"
                    
                    characters.append({
                        'english_name': eng_name,
                        'detail_url': detail_url,
                        'image_url': img_url,
                        'release_date': release_date
                    })
                    
                except Exception as e:
                    print(f"âš ï¸ í–‰ íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue
            
            print(f"âœ… ìºë¦­í„° ëª©ë¡ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {len(characters)}ê°œ")
            return characters
            
        except Exception as e:
            print(f"âŒ ìºë¦­í„° ëª©ë¡ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
            return []
    
    def clean_scraped_data(self, data):
        """ìŠ¤í¬ë˜í•‘ëœ ë°ì´í„° ì •ë¦¬ ë° í‘œì¤€í™” (ì™„ì „ ìë™í™”)"""
        cleaned_data = {}
        
        # ê¸°ë³¸ ë°ì´í„° ë³µì‚¬
        for key, value in data.items():
            cleaned_data[key] = value
        
        # íŒŒì¼ëª… ì•ˆì „í™” í•¨ìˆ˜
        def safe_filename(name):
            if not name:
                return "unknown"
            unsafe_chars = r'<>:"/\|?*'
            safe_name = str(name)
            for char in unsafe_chars:
                safe_name = safe_name.replace(char, '_')
            safe_name = safe_name.replace(' ', '_')
            safe_name = re.sub(r'_+', '_', safe_name)
            return safe_name.strip('_')
        
        # í¬ê·€ë„ í‘œì¤€í™” ë° 3-4ì„± ì—¬ë¶€ í™•ì¸
        def normalize_rarity_and_check(rarity_str):
            if not isinstance(rarity_str, str):
                return str(rarity_str), False
            
            rarity_str = rarity_str.strip()
            has_sa = 'SA' in rarity_str.upper() or 'ì„±ë„ê°ì„±' in rarity_str or 'Stellar Awakened' in rarity_str
            
            nums = re.findall(r'(\d)(?=â˜…)', rarity_str)
            if nums:
                max_star = max(int(n) for n in nums)
                normalized = f"{max_star}â˜…{' SA' if has_sa else ''}".strip()
                is_3_4_star = max_star in [3, 4]
                return normalized, is_3_4_star
            
            return rarity_str, False
        
        # í¼ìŠ¤ë„ë¦¬í‹° ì •ë¦¬ (ì†ì„±/ë¬´ê¸° í‚¤ì›Œë“œ ì œì™¸)
        def clean_personalities(personality_str):
            if not isinstance(personality_str, str) or not personality_str:
                return []
            
            personalities = [p.strip() for p in personality_str.split(',') if p.strip()]
            
            element_keywords = [
                'fire', 'water', 'earth', 'wind', 'light', 'dark', 'crystal', 'thunder', 'shade',
                'ë•…', 'ë¶ˆ', 'ë°”ëŒ', 'ë¬¼', 'ë¹›', 'ì–´ë‘ ', 'ë²ˆê°œ', 'í¬ë¦¬ìŠ¤íƒˆ', 'í™”', 'ìˆ˜', 'ì§€', 'í’'
            ]
            weapon_keywords = [
                'sword', 'katana', 'axe', 'hammer', 'spear', 'bow', 'staff', 'fist', 'lance',
                'ê²€', 'ë„', 'ë„ë¼', 'ë§ì¹˜', 'ì°½', 'í™œ', 'ì§€íŒ¡ì´', 'ì£¼ë¨¹', 'ëœìŠ¤', 'ê¶Œê°‘'
            ]
            
            clean_personalities = []
            for personality in personalities:
                personality_lower = personality.lower()
                is_element = any(keyword in personality_lower for keyword in element_keywords)
                is_weapon = any(keyword in personality_lower for keyword in weapon_keywords)
                
                if not is_element and not is_weapon and len(personality) > 1:
                    clean_personalities.append(personality)
            
            return clean_personalities
        
        # ì¶œì‹œì¼ í‘œì¤€í™” í•¨ìˆ˜
        def standardize_release_date(date_str):
            if not date_str or not isinstance(date_str, str):
                return ""
            
            date_match = re.search(r'(\d{4})[/-](\d{1,2})[/-](\d{1,2})', date_str)
            if date_match:
                year, month, day = date_match.groups()
                return f"{year}/{int(month):02d}/{int(day):02d}"
            return date_str
        
        # 1. í¬ê·€ë„ ì •ë¦¬ (3-4ì„± ì—¬ë¶€ í™•ì¸)
        if 'rarity' in cleaned_data:
            normalized_rarity, is_3_4_star = normalize_rarity_and_check(cleaned_data['rarity'])
            cleaned_data['rarity'] = normalized_rarity
            cleaned_data['is_3_4_star'] = is_3_4_star
        
        # 2. í¼ìŠ¤ë„ë¦¬í‹° ì •ë¦¬
        if 'personality' in cleaned_data:
            clean_pers = clean_personalities(cleaned_data['personality'])
            cleaned_data['personality'] = ', '.join(clean_pers) if clean_pers else ""
            cleaned_data['personality_list'] = clean_pers
        
        # 3. ì¶œì‹œì¼ í‘œì¤€í™”
        if 'release_date' in cleaned_data:
            cleaned_data['release_date'] = standardize_release_date(cleaned_data['release_date'])
        
        # 4. ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±
        if 'korean_name' in cleaned_data:
            cleaned_data['safe_filename'] = safe_filename(cleaned_data['korean_name'])
        elif 'english_name' in cleaned_data:
            cleaned_data['safe_filename'] = safe_filename(cleaned_data['english_name'])
        else:
            cleaned_data['safe_filename'] = "unknown_character"
        
        # 5. ë°ì´í„° ê²€ì¦ ë° ì™„ì„±ë„ í™•ì¸
        required_fields = ['korean_name', 'english_name', 'element', 'weapon']
        completeness_score = sum(1 for field in required_fields if cleaned_data.get(field))
        cleaned_data['data_completeness'] = completeness_score / len(required_fields)
        
        return cleaned_data

    def scrape_character_details(self, detail_url, eng_name):
        """ìºë¦­í„° ìƒì„¸ í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ (ì•„ì´ì½˜ í¬í•¨)"""
        try:
            response = requests.get(detail_url, headers=self.headers, timeout=30)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            
            data = {}
            element_icons = []
            weapon_icons = []
            
            # ë‹¤ì–‘í•œ í…Œì´ë¸”ì—ì„œ ë°ì´í„° ì°¾ê¸°
            tables = soup.find_all('table')
            
            # ìœ„ì¹˜ ê¸°ë°˜ íŒŒì‹± (ë ˆê±°ì‹œ ë°©ì‹) - ì™„ì „ ë³µì›
            element_icons = []
            element_alts = []  # ALT í…ìŠ¤íŠ¸ë„ ì €ì¥
            weapon_icons = []
            
            # ë©”ì¸ ìºë¦­í„° ì •ë³´ í…Œì´ë¸” ì°¾ê¸° (anotherTable, wikitable, infobox)
            main_tables = soup.find_all('table', class_=['anotherTable', 'wikitable', 'infobox'])
            print(f"    ğŸ” {len(main_tables)}ê°œ ë©”ì¸ í…Œì´ë¸” ë°œê²¬")
            
            for table_idx, table in enumerate(main_tables):
                rows = table.find_all('tr')
                table_class = table.get('class', ['ì—†ìŒ'])
                print(f"      ğŸ“‹ í…Œì´ë¸” {table_idx} (class={table_class}): {len(rows)}ê°œ í–‰")
                
                # ê° í–‰ì„ í™•ì¸í•˜ì—¬ 3ë²ˆì§¸ ì…€(ì¸ë±ìŠ¤ 2)ì— ì´ë¯¸ì§€ê°€ ìˆëŠ” í–‰ ì²˜ë¦¬
                for row_idx, row in enumerate(rows):
                    cells = row.find_all(['th', 'td'])
                    
                    # 3ê°œ ì´ìƒì˜ ì…€ì´ ìˆëŠ” í–‰ì—ì„œ 3ë²ˆì§¸ ì…€ í™•ì¸
                    if len(cells) >= 3:
                        element_equipment_cell = cells[2]
                        ee_icon_tags = element_equipment_cell.find_all('img')
                        
                        if ee_icon_tags:  # ì´ë¯¸ì§€ê°€ ìˆëŠ” í–‰ë§Œ ì²˜ë¦¬
                            print(f"        ğŸ¯ í…Œì´ë¸” {table_idx}, í–‰ {row_idx}: 3ë²ˆì§¸ ì…€ì—ì„œ {len(ee_icon_tags)}ê°œ ì´ë¯¸ì§€ ë°œê²¬")
                            
                            for img_tag in ee_icon_tags:
                                src = img_tag.get('src', '')
                                alt = img_tag.get('alt', '')
                                
                                if src:
                                    # ë ˆê±°ì‹œ ë°©ì‹: ì¡°ê±´ ì—†ì´ ëª¨ë“  ì•„ì´ì½˜ ë‹¤ìš´ë¡œë“œ
                                    icon_path = self.download_icon(src, alt, "elements_equipment")
                                    if icon_path:
                                        # ì¤‘ë³µ ë°©ì§€ (ë ˆê±°ì‹œ ë°©ì‹: ê²½ë¡œì™€ ALTë¥¼ í•¨ê»˜ ì €ì¥)
                                        if icon_path not in element_icons:
                                            element_icons.append(icon_path)
                                            element_alts.append(alt)  # ALT í…ìŠ¤íŠ¸ë„ í•¨ê»˜ ì €ì¥
                                            print(f"          âœ… ì•„ì´ì½˜ ì¶”ê°€: {os.path.basename(icon_path)} (ALT: {alt})")
                                        else:
                                            print(f"          ğŸ”„ ì¤‘ë³µ ì•„ì´ì½˜ ìŠ¤í‚µ: {os.path.basename(icon_path)}")
            
            # ë¬´ê¸° ì•„ì´ì½˜ì€ element_iconsì—ì„œ ë³µì‚¬ (ë ˆê±°ì‹œ ë°©ì‹)
            weapon_icons = element_icons.copy()
            
            # ë ˆê±°ì‹œ ë°©ì‹: ë‹¤ìš´ë¡œë“œëœ ì•„ì´ì½˜ì„ ë§¤í•‘ í…Œì´ë¸”ë¡œ ë¶„ë¥˜
            classified_elements = []
            classified_element_icons = []
            classified_weapons = []
            classified_weapon_icons = []
            classified_armors = []
            classified_armor_icons = []
            
            print(f"    ğŸ” {len(element_icons)}ê°œ ë‹¤ìš´ë¡œë“œëœ ì•„ì´ì½˜ ë¶„ë¥˜ ì¤‘...")
            
            for i, (icon_path, alt_text) in enumerate(zip(element_icons, element_alts)):
                filename = os.path.basename(icon_path)
                print(f"      ğŸ” ë¶„ë¥˜ ì¤‘: {filename} (ALT: {alt_text})")
                
                # 1ìˆœìœ„: ALT í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ë¥˜ (ë ˆê±°ì‹œ ë°©ì‹)
                if alt_text in ALT_TEXT_MAPPING:
                    category, name = ALT_TEXT_MAPPING[alt_text]
                    if category == "element":
                        classified_elements.append(name)
                        classified_element_icons.append(icon_path)
                        print(f"        âœ… ì†ì„± (ALT): {name}")
                    elif category == "weapon":
                        classified_weapons.append(name)
                        classified_weapon_icons.append(icon_path)
                        print(f"        âš”ï¸ ë¬´ê¸° (ALT): {name}")
                
                # 2ìˆœìœ„: íŒŒì¼ëª… ê¸°ë°˜ ë¶„ë¥˜ (ALTê°€ ë§¤í•‘ì— ì—†ëŠ” ê²½ìš°)
                elif filename in ELEMENT_MAPPING:
                    element_name = ELEMENT_MAPPING[filename]
                    classified_elements.append(element_name)
                    classified_element_icons.append(icon_path)
                    print(f"        âœ… ì†ì„± (íŒŒì¼ëª…): {element_name}")
                
                elif filename in WEAPON_MAPPING:
                    weapon_name = WEAPON_MAPPING[filename]
                    classified_weapons.append(weapon_name)
                    classified_weapon_icons.append(icon_path)
                    print(f"        âš”ï¸ ë¬´ê¸° (íŒŒì¼ëª…): {weapon_name}")
                
                elif filename in ARMOR_MAPPING:
                    armor_name = ARMOR_MAPPING[filename]
                    classified_armors.append(armor_name)
                    classified_armor_icons.append(icon_path)
                    print(f"        ğŸ›¡ï¸ ë°©ì–´êµ¬ (íŒŒì¼ëª…): {armor_name}")
                    
                else:
                    print(f"        â“ ë¯¸ë¶„ë¥˜: {filename} (ALT: {alt_text})")
                    # ë¯¸ë¶„ë¥˜ ì•„ì´ì½˜ì€ ì»¨í…ìŠ¤íŠ¸ì— ë”°ë¼ ì¶”ê°€ ì²˜ë¦¬
                    if any(keyword in alt_text.lower() for keyword in ['light', 'shadow', 'dark']):
                        # Light/Shadow ê´€ë ¨ì€ ì†ì„±ìœ¼ë¡œ ë¶„ë¥˜
                        element_name = alt_text.replace(' Icon.png', '').replace('_', ' ')
                        classified_elements.append(element_name)
                        classified_element_icons.append(icon_path)
                        print(f"        âœ… ì†ì„±(ì¶”ë¡ ): {element_name}")
            
            # ë¶„ë¥˜ ê²°ê³¼ë¡œ ë°ì´í„° ì—…ë°ì´íŠ¸
            element_icons = classified_element_icons
            weapon_icons = classified_weapon_icons
            
            # í…ìŠ¤íŠ¸ ì •ë³´ë„ ë¶„ë¥˜ëœ ê²°ê³¼ë¡œ ì—…ë°ì´íŠ¸
            if classified_elements:
                data['elements'] = ', '.join(classified_elements)
            if classified_weapons:
                data['weapons'] = ', '.join(classified_weapons)
            else:
                # ë¬´ê¸°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
                data['weapons'] = 'Obtain'
            
            # í—¤ë” ê¸°ë°˜ í…ìŠ¤íŠ¸ íŒŒì‹± (í¬ê·€ë„ ë“± ì¶”ê°€ ì •ë³´)
            for table in tables:
                rows = table.find_all('tr')
                
                for row in rows:
                    cells = row.find_all(['th', 'td'])
                    if len(cells) < 2:
                        continue
                    
                    # í—¤ë”ì™€ ê°’ ë¶„ë¦¬
                    header_cell = cells[0]
                    value_cell = cells[-1] if len(cells) > 1 else None
                    
                    if not header_cell or not value_cell:
                        continue
                    
                    header_text = header_cell.get_text(strip=True).lower()
                    value_text = value_cell.get_text(strip=True)
                    
                    # í¬ê·€ë„ ì°¾ê¸°
                    if any(keyword in header_text for keyword in ['rarity', 'í¬ê·€ë„', 'star', 'ë³„']):
                        if 'â˜…' in value_text or 'star' in value_text.lower():
                            data['rarity'] = value_text
                        elif 'SA' in value_text.upper() or 'Stellar Awakened' in value_text:
                            data['rarity'] = "5â˜… SA"
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            if 'rarity' not in data or not data['rarity']:
                data['rarity'] = '5â˜…'
            if 'elements' not in data or not data['elements']:
                data['elements'] = 'N/A'
            if 'weapons' not in data or not data['weapons']:
                data['weapons'] = 'Obtain'
            
            # ê³ í™”ì§ˆ ì´ë¯¸ì§€ ì¶”ì¶œ ë° ë‹¤ìš´ë¡œë“œ
            img_tag = soup.find('img', class_='thumbimage') or soup.find('img', class_='infobox-image')
            if img_tag:
                img_src = img_tag.get('src', '')
                if img_src.startswith('http'):
                    data['high_res_image_url'] = img_src
                else:
                    data['high_res_image_url'] = urljoin(BASE_URL, img_src)
                
                # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                kor_name = data.get('korean_name', eng_name)
                image_path = self.download_character_image(data['high_res_image_url'], kor_name, eng_name)
                if image_path:
                    data['image_path'] = image_path
            
            # ë°ì´í„° ì •ë¦¬
            cleaned_data = self.clean_scraped_data(data)
            
            # ì•„ì´ì½˜ ì •ë³´ ì¶”ê°€
            cleaned_data['element_icons'] = element_icons
            cleaned_data['weapon_icons'] = weapon_icons
            
            # ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
            if cleaned_data:
                print(f"  ğŸ“Š {eng_name}: í¬ê·€ë„={cleaned_data.get('rarity', 'N/A')}, ì†ì„±={cleaned_data.get('elements', 'N/A')}, ë¬´ê¸°={cleaned_data.get('weapons', 'N/A')}")
                if element_icons:
                    print(f"    ğŸ¯ ì†ì„± ì•„ì´ì½˜: {len(element_icons)}ê°œ")
                if weapon_icons:
                    print(f"    âš”ï¸ ë¬´ê¸° ì•„ì´ì½˜: {len(weapon_icons)}ê°œ")
                if cleaned_data.get('image_path'):
                    print(f"    ğŸ–¼ï¸ ì´ë¯¸ì§€: {cleaned_data['image_path']}")
            
            return cleaned_data
            
        except Exception as e:
            print(f"âš ï¸ {eng_name} ìƒì„¸ í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
            return {}
    
    def scrape_all_personalities(self):
        """ì „ì²´ í¼ìŠ¤ë„ë¦¬í‹° ë°ì´í„° ìŠ¤í¬ë˜í•‘"""
        print("ğŸ­ í¼ìŠ¤ë„ë¦¬í‹° ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì¤‘...")
        try:
            response = requests.get(PERSONALITY_URL, headers=self.headers, timeout=30)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # wikitable í´ë˜ìŠ¤ë¥¼ ê°€ì§„ í…Œì´ë¸”ë“¤ ì°¾ê¸°
            tables = soup.find_all('table', class_='wikitable')
            character_personalities = {}
            
            for table in tables:
                rows = table.find_all('tr')[1:]  # í—¤ë” ì œì™¸
                
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    if len(cells) >= 2:
                        # í¼ìŠ¤ë„ë¦¬í‹° ì´ë¦„
                        personality_cell = cells[0]
                        personality_eng = personality_cell.get_text(strip=True)
                        personality_kor = self.personality_mapping.get(personality_eng, personality_eng)
                        
                        # ìºë¦­í„° ëª©ë¡
                        characters_cell = cells[1]
                        character_links = characters_cell.find_all('a')
                        characters_found = []
                        
                        for link in character_links:
                            href = link.get('href', '')
                            if (href.startswith('/w/') and 
                                'Character' not in href and 
                                'Personality' not in href and
                                'Special:' not in href and
                                'Category:' not in href):
                                
                                char_name = link.get_text(strip=True)
                                if char_name and len(char_name) > 1:
                                    characters_found.append(char_name)
                        
                        # ê° ìºë¦­í„°ì— í¼ìŠ¤ë„ë¦¬í‹° ì¶”ê°€
                        for char_name in characters_found:
                            if char_name not in character_personalities:
                                character_personalities[char_name] = []
                            character_personalities[char_name].append(personality_kor)
            
            print(f"âœ… í¼ìŠ¤ë„ë¦¬í‹° ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {len(character_personalities)}ëª…")
            return character_personalities
            
        except Exception as e:
            print(f"âŒ í¼ìŠ¤ë„ë¦¬í‹° ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
            return {}
    
    def create_excel_with_images(self, characters):
        """ì´ë¯¸ì§€ í¬í•¨ ì—‘ì…€ íŒŒì¼ ìƒì„±"""
        print("ğŸ“Š ì—‘ì…€ íŒŒì¼ ìƒì„± ì¤‘...")
        try:
            wb = Workbook()
            ws = wb.active
            ws.title = "Characters"
            
            headers = ['English Name', 'Korean Name', 'Rarity', 'Elements', 'Weapons', 'Personalities', 'Image Path']
            ws.append(headers)
            
            for char in characters:
                row = [
                    char.get('english_name', ''),
                    char.get('korean_name', ''),
                    char.get('rarity', ''),
                    char.get('elements', ''),
                    char.get('weapons', ''),
                    char.get('personalities', ''),
                    char.get('image_path', '')
                ]
                ws.append(row)
            
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 50)
                ws.column_dimensions[column_letter].width = adjusted_width
            
            excel_path = CSV_DIR / "another_eden_characters_detailed.xlsx"
            wb.save(excel_path)
            print(f"âœ… ì—‘ì…€ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {excel_path}")
            return excel_path
        except Exception as e:
            print(f"âŒ ì—‘ì…€ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def generate_csv_files(self, characters, personality_data):
        """í†µì¼ëœ CSV íŒŒì¼ë“¤ ìƒì„± (í€´ì¦ˆìš© + ë£°ë ›ìš© + ì¶œì‹œì¼ í¬í•¨)"""
        print("ğŸ“‹ í†µì¼ëœ CSV íŒŒì¼ë“¤ ìƒì„± ì¤‘...")
        
        # 1. í€´ì¦ˆìš© ë°ì´í„° (ì¶œì‹œì¼ ì¶”ê°€)
        quiz_data = []
        for char in characters:
            # í¼ìŠ¤ë„ë¦¬í‹° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            base_eng_name = re.sub(r'\s*\(.*\)$', '', char.get('english_name', '')).strip()
            personalities = personality_data.get(base_eng_name, [])
            
            # í¼ìŠ¤ë„ë¦¬í‹° í•œê¸€ ë³€í™˜
            korean_personalities = []
            for personality in personalities:
                korean_personality = self.personality_mapping.get(personality, personality)
                korean_personalities.append(korean_personality)
            
            quiz_data.append({
                'ìºë¦­í„°ëª…': char.get('korean_name', ''),
                'English_Name': char.get('english_name', ''),
                'ìºë¦­í„°ì•„ì´ì½˜ê²½ë¡œ': char.get('image_path', ''),
                'í¬ê·€ë„': char.get('rarity', '5â˜…'),
                'ì†ì„±ëª…ë¦¬ìŠ¤íŠ¸': char.get('elements', ''),
                'ë¬´ê¸°ëª…ë¦¬ìŠ¤íŠ¸': char.get('weapons', 'Obtain'),
                'í¼ìŠ¤ë„ë¦¬í‹°ë¦¬ìŠ¤íŠ¸': ', '.join(korean_personalities),
                'ì¶œì‹œì¼': char.get('release_date', '')
            })
        
        quiz_df = pd.DataFrame(quiz_data)
        quiz_csv_path = CSV_DIR / "eden_quiz_data.csv"
        quiz_df.to_csv(quiz_csv_path, index=False, encoding='utf-8-sig')
        print(f"âœ… í€´ì¦ˆ ë°ì´í„° ì €ì¥: {quiz_csv_path}")

        # 2. ë£°ë ›ìš© ë°ì´í„° (ì•„ì´ì½˜ í¬í•¨ í™•ì¥ êµ¬ì¡° + ì¶œì‹œì¼)
        roulette_data = []
        for char in characters:
            # í¼ìŠ¤ë„ë¦¬í‹° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            base_eng_name = re.sub(r'\s*\(.*\)$', '', char.get('english_name', '')).strip()
            personalities = personality_data.get(base_eng_name, [])
            
            # í¼ìŠ¤ë„ë¦¬í‹° í•œê¸€ ë³€í™˜
            korean_personalities = []
            for personality in personalities:
                korean_personality = self.personality_mapping.get(personality, personality)
                korean_personalities.append(korean_personality)
            
            # ì•„ì´ì½˜ ê²½ë¡œ ìƒì„± (ì‹¤ì œ ìŠ¤í¬ë˜í•‘ëœ ì•„ì´ì½˜ ì‚¬ìš©)
            element_icons = char.get('element_icons', [])
            weapon_icons = char.get('weapon_icons', [])
            armor_icons = []
            
            # ë ˆê±°ì‹œ ë°©ì‹: ì‹¤ì œ ë‹¤ìš´ë¡œë“œëœ ì•„ì´ì½˜ë§Œ ì‚¬ìš© (ê°€ìƒ ê²½ë¡œ ìƒì„± ì œê±°)
            # ê°€ìƒ ê²½ë¡œ ìƒì„±í•˜ì§€ ì•ŠìŒ - ì‹¤ì œ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ë§Œ CSVì— í¬í•¨
            
            roulette_data.append({
                'ìºë¦­í„°ëª…': char.get('korean_name', ''),
                'English_Name': char.get('english_name', ''),
                'ìºë¦­í„°ì•„ì´ì½˜ê²½ë¡œ': char.get('image_path', ''),
                'í¬ê·€ë„': char.get('rarity', '5â˜…'),
                'ì†ì„±ëª…ë¦¬ìŠ¤íŠ¸': char.get('elements', ''),
                'ì†ì„±_ì•„ì´ì½˜ê²½ë¡œë¦¬ìŠ¤íŠ¸': '|'.join(element_icons) if element_icons else '',
                'ë¬´ê¸°ëª…ë¦¬ìŠ¤íŠ¸': char.get('weapons', 'Obtain'),
                'ë¬´ê¸°_ì•„ì´ì½˜ê²½ë¡œë¦¬ìŠ¤íŠ¸': '|'.join(weapon_icons) if weapon_icons else '',
                'ë°©ì–´êµ¬ëª…ë¦¬ìŠ¤íŠ¸': '',  # í˜„ì¬ ìŠ¤í¬ë˜í¼ì—ì„œ ë°©ì–´êµ¬ ì •ë³´ ì—†ìŒ
                'ë°©ì–´êµ¬_ì•„ì´ì½˜ê²½ë¡œë¦¬ìŠ¤íŠ¸': '|'.join(armor_icons) if armor_icons else '',
                'í¼ìŠ¤ë„ë¦¬í‹°ë¦¬ìŠ¤íŠ¸': ', '.join(korean_personalities),
                'ì¶œì‹œì¼': char.get('release_date', '')
            })
        
        roulette_df = pd.DataFrame(roulette_data)
        roulette_csv_path = CSV_DIR / "eden_roulette_data.csv"
        roulette_df.to_csv(roulette_csv_path, index=False, encoding='utf-8-sig')
        print(f"âœ… ë£°ë › ë°ì´í„° ì €ì¥: {roulette_csv_path}")
        
        # 3. í¼ìŠ¤ë„ë¦¬í‹° ì „ìš© CSV (ë£°ë › ì•±ìš©)
        personality_data_list = []
        for char in characters:
            base_eng_name = re.sub(r'\s*\(.*\)$', '', char.get('english_name', '')).strip()
            personalities = personality_data.get(base_eng_name, [])
            
            korean_personalities = []
            for personality in personalities:
                korean_personality = self.personality_mapping.get(personality, personality)
                korean_personalities.append(korean_personality)
            
            personality_data_list.append({
                'Korean_Name': char.get('korean_name', ''),
                'English_Name': char.get('english_name', ''),
                'Personalities_List': ', '.join(korean_personalities)
            })
        
        personality_df = pd.DataFrame(personality_data_list)
        personality_csv_path = CSV_DIR / "character_personalities.csv"
        personality_df.to_csv(personality_csv_path, index=False, encoding='utf-8-sig')
        print(f"âœ… í¼ìŠ¤ë„ë¦¬í‹° ë°ì´í„° ì €ì¥: {personality_csv_path}")

        # 4. í†µí•© í¼ìŠ¤ë„ë¦¬í‹° ë°ì´í„° (ì¤‘ë³µ ì œê±°ëœ ë²„ì „)
        personality_list = []
        for char_name, personalities in personality_data.items():
            personality_list.append({
                'Character': self.convert_to_korean(char_name),
                'Personalities_Count': len(personalities),
                'Personalities_List': '|'.join(personalities)
            })
        
        personality_summary_df = pd.DataFrame(personality_list)
        personality_summary_df.sort_values('Personalities_Count', ascending=False, inplace=True)
        personality_summary_csv_path = CSV_DIR / "character_personalities_summary.csv"
        personality_summary_df.to_csv(personality_summary_csv_path, index=False, encoding='utf-8-sig')
        print(f"âœ… í¼ìŠ¤ë„ë¦¬í‹° ìš”ì•½ ë°ì´í„° ì €ì¥: {personality_summary_csv_path}")
        
        return quiz_csv_path, roulette_csv_path, personality_csv_path

    def organize_scraped_images(self, characters):
        """ìŠ¤í¬ë˜í•‘ëœ ì´ë¯¸ì§€ ìë™ ì •ë¦¬ (ë ˆê±°ì‹œ ê¸°ëŠ¥ ë³µì›)"""
        from .image_organizer import ImageOrganizer
        
        print("ğŸ—‚ï¸ ì´ë¯¸ì§€ ìë™ ì •ë¦¬ ì‹œì‘...")
        try:
            organizer = ImageOrganizer(self.project_root)
            
            # 1. ë°±ì—… ì´ë¯¸ì§€ë“¤ ë³µì‚¬
            organizer.copy_backup_images()
            
            # 2. CSV ê¸°ë°˜ ì´ë¯¸ì§€ ì •ë¦¬ 
            csv_path = CSV_DIR / "eden_quiz_data.csv"
            if csv_path.exists():
                organizer.create_organized_folders(csv_path)
            else:
                print("âš ï¸ í€´ì¦ˆ ë°ì´í„° CSVê°€ ì—†ì–´ ì´ë¯¸ì§€ ì •ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def run_full_scraping(self):
        """ì „ì²´ ìŠ¤í¬ë˜í•‘ ì‹¤í–‰ (ì´ë¯¸ì§€ ì •ë¦¬ í¬í•¨)"""
        print("ğŸš€ Another Eden í†µí•© ìŠ¤í¬ë˜í¼ ì‹œì‘")
        print("=" * 60)
        
        self.load_name_mapping()
        self.load_personality_mapping()
        
        characters = self.scrape_character_list()
        if not characters:
            print("âŒ ìºë¦­í„° ë°ì´í„° ì—†ìŒ")
            return False
        
        # ì „ì²´ ìºë¦­í„° ì²˜ë¦¬ (í…ŒìŠ¤íŠ¸ ì™„ë£Œ)
        print("ğŸš€ ì „ì²´ ìºë¦­í„° ì²˜ë¦¬ ëª¨ë“œ: 372ê°œ ìºë¦­í„°ë¥¼ ëª¨ë‘ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        # characters = characters[:10]  # í…ŒìŠ¤íŠ¸ ëª¨ë“œ ë¹„í™œì„±í™”
        
        personality_data = self.scrape_all_personalities()
        
        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ (ì¤‘ë³µ ì²´í¬ìš©)
        existing_data = {}
        quiz_csv_path = CSV_DIR / "eden_quiz_data.csv"
        if quiz_csv_path.exists():
            try:
                existing_df = pd.read_csv(quiz_csv_path, encoding='utf-8-sig')
                for _, row in existing_df.iterrows():
                    existing_data[row['English_Name']] = True
                print(f"ğŸ“‹ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ: {len(existing_data)}ê°œ ìºë¦­í„°")
            except Exception as e:
                print(f"âš ï¸ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # --- Phase 1: Scrape all data ---
        print("\n--- Phase 1: ëª¨ë“  ë°ì´í„° ìŠ¤í¬ë˜í•‘ ---")
        all_details = []
        print("ï¿½ï¿½ ìºë¦­í„° ìƒì„¸ ì •ë³´ ì¼ê´„ ìŠ¤í¬ë˜í•‘ ì¤‘...")
        
        skipped_count = 0
        scraped_count = 0
        
        for i, char in enumerate(characters, 1):
            eng_name = char['english_name']
            
            # ì¤‘ë³µ ì²´í¬ (ê¸°ì¡´ ë°ì´í„°ê°€ ìˆê³  ì´ë¯¸ì§€ë„ ì¡´ì¬í•˜ë©´ ìŠ¤í‚µ)
            if eng_name in existing_data:
                # ì´ë¯¸ì§€ íŒŒì¼ë„ ì²´í¬
                normalized_name = self.normalize_image_filename(char.get('korean_name', ''), eng_name)
                image_path = IMAGE_DIR / normalized_name
                
                if image_path.exists() and image_path.stat().st_size > 0:
                    print(f"[{i}/{len(characters)}] {eng_name} - ì´ë¯¸ ì²˜ë¦¬ë¨, ìŠ¤í‚µ")
                    skipped_count += 1
                    # ê¸°ì¡´ ë°ì´í„° ì‚¬ìš©
                    existing_char_data = {
                        'english_name': eng_name,
                        'korean_name': char.get('korean_name', ''),
                        'image_path': str(image_path.relative_to(self.project_root).as_posix())
                    }
                    all_details.append(existing_char_data)
                    continue
            
            print(f"[{i}/{len(characters)}] {eng_name} ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
            details = self.scrape_character_details(char['detail_url'], eng_name)
            all_details.append(details)
            scraped_count += 1
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥
            if i % 50 == 0:
                print(f"  ğŸ“Š ì§„í–‰ë¥ : {i}/{len(characters)} ({i/len(characters)*100:.1f}%) - ìŠ¤í‚µ: {skipped_count}, ìŠ¤í¬ë˜í•‘: {scraped_count}")
            
            time.sleep(0.5)  # ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•´ ëŒ€ê¸° ì‹œê°„ ì¦ê°€

        # --- Phase 2: Process all data ---
        print("\n--- Phase 2: ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ ---")
        processed_characters = []
        for i, char_data in enumerate(characters):
            eng_name = char_data['english_name']
            kor_name = self.convert_to_korean(eng_name)
            details = all_details[i]

            # Get personalities - ìŠ¤íƒ€ì¼ ì ‘ë¯¸ì‚¬ ì œê±° í›„ ë§¤ì¹­
            base_eng_name = re.sub(r'\s*\(.*\)$', '', eng_name).strip()
            personalities = personality_data.get(base_eng_name, [])
            
            # í¼ìŠ¤ë„ë¦¬í‹° í•œê¸€ ë³€í™˜
            korean_personalities = []
            for personality in personalities:
                korean_personality = self.personality_mapping.get(personality, personality)
                korean_personalities.append(korean_personality)

            processed_char = {
                **char_data,
                'korean_name': kor_name,
                'rarity': details.get('rarity', ''),
                'elements': details.get('elements', ''),
                'weapons': details.get('weapons', ''),
                'personalities': ', '.join(korean_personalities),
                'high_res_image_url': details.get('high_res_image_url', ''),
                'image_path': ''  # Initialize path
            }
            processed_characters.append(processed_char)

        # --- Phase 3: Download images ---
        print("\n--- Phase 3: ëª¨ë“  ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ---")
        for i, char in enumerate(processed_characters, 1):
            kor_name = char['korean_name']
            eng_name = char['english_name']
            image_url = char.get('high_res_image_url') or char.get('image_url')
            
            print(f"[{i}/{len(processed_characters)}] {kor_name} ({eng_name}) ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            if image_url:
                image_path = self.download_character_image(image_url, kor_name=kor_name, eng_name=eng_name)
                char['image_path'] = image_path or ''
            else:
                print(f"  âŒ ì´ë¯¸ì§€ URL ì—†ìŒ")
        
        # Replace original characters list with the fully processed one
        characters = processed_characters
        
        excel_path = self.create_excel_with_images(characters)
        csv_paths = self.generate_csv_files(characters, personality_data)
        
        # --- Phase 4: ì´ë¯¸ì§€ ìë™ ì •ë¦¬ (ë ˆê±°ì‹œ ê¸°ëŠ¥ ë³µì›) ---
        print("\n--- Phase 4: ì´ë¯¸ì§€ ìë™ ì •ë¦¬ ---")
        self.organize_scraped_images(characters)
        
        print("\nğŸ‰ í†µí•© ìŠ¤í¬ë˜í•‘ ì™„ë£Œ!")
        print("=" * 60)
        print(f"ğŸ“Š ì´ ìºë¦­í„° ìˆ˜: {len(characters)}")
        if excel_path:
            print(f"ğŸ’¾ ì—‘ì…€ íŒŒì¼: {excel_path}")
        if csv_paths:
            print(f"ğŸ’¾ CSV íŒŒì¼ë“¤: {', '.join(map(str, csv_paths))}")
        print(f"ğŸ—‚ï¸ ì •ë¦¬ëœ ì´ë¯¸ì§€: {IMAGE_DIR.parent}/organized_character_art")
        
        return True


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    scraper = MasterScraper()
    success = scraper.run_full_scraping()
    return success


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
