#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ”§ Another Eden ë§ˆìŠ¤í„° ìŠ¤í¬ë˜í¼
ìŠ¤í¬ë˜í•‘ â†’ ì´ë¯¸ì§€ ì •ë¦¬ â†’ CSV ìƒì„± â†’ ë°ì´í„° ì •ë¦¬ê¹Œì§€ ëª¨ë“  ì‘ì—…ì„ í†µí•© ì²˜ë¦¬
"""

import os
import sys
import time
import requests
import pandas as pd
from pathlib import Path
from bs4 import BeautifulSoup
from urllib.parse import urljoin, unquote, parse_qs, urlparse
import re
import unicodedata
import mimetypes
from openpyxl import Workbook
import traceback
import urllib3
import ssl


# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent.resolve()
SCRAPING_DIR = PROJECT_ROOT / "01_scraping"
DATA_DIR = PROJECT_ROOT / "04_data"
CSV_DIR = DATA_DIR / "csv"
IMAGE_DIR = DATA_DIR / "images" / "character_art"

# ìŠ¤í¬ë˜í•‘ ì„¤ì •
BASE_URL = "https://anothereden.wiki"
TARGET_URL = "https://anothereden.wiki/w/Characters"
PERSONALITY_URL = "https://anothereden.wiki/w/Characters/Personality"


class MasterScraper:
    """í†µí•© ë§ˆìŠ¤í„° ìŠ¤í¬ë˜í¼"""
    
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        self.character_data = []
        self.name_mapping = {}
        self.personality_mapping = {}
        self.setup_directories()
        
    def setup_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        for directory in [CSV_DIR, IMAGE_DIR]:
            directory.mkdir(parents=True, exist_ok=True)
        
        # ì´ë¯¸ì§€ í•˜ìœ„ í´ë”
        (IMAGE_DIR / "icons").mkdir(exist_ok=True)
        (IMAGE_DIR / "elements_equipment").mkdir(exist_ok=True)
        
        print("ë””ë ‰í† ë¦¬ ì„¤ì • ì™„ë£Œ")
        print(f"   ë°ì´í„°: {CSV_DIR}")
        print(f"   ì´ë¯¸ì§€: {IMAGE_DIR}")
    
    def load_name_mapping(self):
        """í•œê¸€ ì´ë¦„ ë§¤í•‘ ë¡œë“œ"""
        mapping_file = CSV_DIR / "Matching_names.csv"
        if mapping_file.exists():
            try:
                df = pd.read_csv(mapping_file, encoding='utf-8-sig')
                for _, row in df.iterrows():
                    if len(row) >= 2:
                        eng_name = str(row.iloc[0]).strip()
                        kor_name = str(row.iloc[1]).strip()
                        if eng_name and kor_name and kor_name != 'nan':
                            self.name_mapping[eng_name.lower()] = kor_name
                print(f"í•œê¸€ ë§¤ì¹­ ë¡œë“œ: {len(self.name_mapping)}ê°œ")
            except Exception as e:
                print(f"ë§¤í•‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
        else:
            print("Matching_names.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    def load_personality_mapping(self):
        """í¼ìŠ¤ë„ë¦¬í‹° ë§¤í•‘ ë¡œë“œ"""
        mapping_file = CSV_DIR / "personality_matching.csv"
        if mapping_file.exists():
            try:
                df = pd.read_csv(mapping_file)
                for _, row in df.iterrows():
                    if 'English' in row and 'Korean' in row:
                        self.personality_mapping[row['English']] = row['Korean']
                print(f"í¼ìŠ¤ë„ë¦¬í‹° ë§¤í•‘ ë¡œë“œ: {len(self.personality_mapping)}ê°œ")
            except Exception as e:
                print(f"í¼ìŠ¤ë„ë¦¬í‹° ë§¤í•‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
        else:
            print("personality_matching.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    def convert_to_korean(self, english_name):
        """ì˜ì–´ ì´ë¦„ì„ í•œê¸€ë¡œ ë³€í™˜ (ìŠ¤íƒ€ì¼ ì ‘ë¯¸ì‚¬ ê³ ë ¤)"""
        if not english_name:
            return english_name
        
        # ìŠ¤íƒ€ì¼ ì ‘ë¯¸ì‚¬ ë¶„ë¦¬
        style_patterns = [
            r'\s+(AS)$', r'\s+(ES)$', r'\s+(NS)$',
            r'\s+(Another\s*Style)$', r'\s+(Extra\s*Style)$',
            r'\s+(Manifestation)$', r'\s+(Alter)$',
        ]
        
        base_name = english_name
        style_suffix = ""
        
        for pattern in style_patterns:
            match = re.search(pattern, english_name, re.IGNORECASE)
            if match:
                style_suffix = " " + match.group(1)
                base_name = english_name[:match.start()]
                break
        
        # í•œê¸€ ë§¤ì¹­
        korean_base = self.name_mapping.get(base_name.lower(), base_name)
        return korean_base + style_suffix
    
    def sanitize_filename(self, name):
        """íŒŒì¼ëª…ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜"""
        name = unicodedata.normalize('NFKC', name)
        name = re.sub(r'[<>:"/\\|?*]', '_', name)
        name = name.strip()
        return name
    
    def check_file_exists(self, filepath):
        """íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (ì¤‘ë³µ ì‹œ None ë°˜í™˜ìœ¼ë¡œ ìŠ¤í‚µ ì²˜ë¦¬)"""
        if os.path.exists(filepath):
            return None  # íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ë©´ None ë°˜í™˜ (ìŠ¤í‚µ)
        return filepath
        
    def download_image(self, image_url, subfolder="", eng_name="Unknown"):
        """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥ (ë””ë²„ê¹… ë° ì•ˆì •ì„± ê°•í™” ë²„ì „)"""
        if not image_url:
            print(f"  - {eng_name}: ì œê³µëœ ì´ë¯¸ì§€ URLì´ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
            return None
        
        # ë‹¤ìš´ë¡œë“œ ì‹œë„ ë¡œê·¸
        print(f"  -> '{eng_name}' ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œë„...")
        full_image_url = urljoin(BASE_URL, image_url)
        
        try:
            # 1. íŒŒì¼ëª… ë¶„ì„ ë° í™•ì •
            parsed_url = urlparse(full_image_url)
            query_params = parse_qs(parsed_url.query)
            image_name_from_f = query_params.get('f', [None])[0]
            
            if image_name_from_f:
                image_name = os.path.basename(unquote(image_name_from_f))
            else:
                image_name = os.path.basename(unquote(parsed_url.path.split('?')[0]))

            if not image_name or image_name.lower() in ["thumb.php", "index.php"]:
                temp_name = unquote(full_image_url.split('/')[-1].split('?')[0])
                image_name = (temp_name[:50] + ".png") if temp_name else "unknown_image.png"

            base_name, ext = os.path.splitext(image_name)

            # í™•ì¥ìê°€ ë¶ˆë¶„ëª…í•  ê²½ìš°, HTTP í—¤ë”ë¥¼ í†µí•´ ì¶”ì¸¡
            if not ext or len(ext) > 5:
                try:
                    head_resp = requests.head(full_image_url, timeout=5, allow_redirects=True)
                    head_resp.raise_for_status()
                    content_type = head_resp.headers.get('Content-Type')
                    if content_type:
                        guessed_ext = mimetypes.guess_extension(content_type.split(';')[0])
                        if guessed_ext:
                            ext = guessed_ext
                except requests.RequestException:
                    ext = ".png"  # ì¶”ì¸¡ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ .pngë¡œ ì„¤ì •
            
            # 2. ì €ì¥ ê²½ë¡œ ë° íŒŒì¼ëª… ì„¤ì •
            korean_name = self.convert_to_korean(base_name)
            safe_name = self.sanitize_filename(korean_name) + ext
            
            save_dir = IMAGE_DIR / subfolder if subfolder else IMAGE_DIR
            save_path = save_dir / safe_name
            
            save_path.parent.mkdir(parents=True, exist_ok=True)
            
            # ì¤‘ë³µ íŒŒì¼ ì²´í¬ (ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìŠ¤í‚µ)
            if self.check_file_exists(str(save_path)) is None:
                # íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš°
                relative_path = save_path.relative_to(PROJECT_ROOT).as_posix()
                print(f"  â­ï¸ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ì—¬ ìŠ¤í‚µ: {relative_path}")
                return str(relative_path)
            
            # 3. ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥
            response = requests.get(full_image_url, headers=self.headers, timeout=30)
            response.raise_for_status()  # 4xx, 5xx ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
            
            with open(save_path, 'wb') as f:
                f.write(response.content)
            
            # 4. ì„±ê³µ ì²˜ë¦¬
            # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œì˜ ìƒëŒ€ ê²½ë¡œë¡œ ì €ì¥ (ì•±ì—ì„œ ì‚¬ìš©í•˜ëŠ” í˜•ì‹)
            relative_path = save_path.relative_to(PROJECT_ROOT).as_posix()
            print(f"  âœ” ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {relative_path}")
            return str(relative_path)
            
        except Exception as e:
            # 5. ì‹¤íŒ¨ ì²˜ë¦¬ (ìƒì„¸ ë¡œê·¸ ì¶œë ¥)
            print("=" * 20 + " ğŸš¨ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ! ğŸš¨ " + "=" * 20)
            print(f"  - ìºë¦­í„° ì´ë¦„: {eng_name}")
            print(f"  - ì‹¤íŒ¨í•œ URL: {full_image_url}")
            print(f"  - ì˜¤ë¥˜ ì¢…ë¥˜: {type(e).__name__}")
            print(f"  - ì˜¤ë¥˜ ë©”ì‹œì§€: {e}")
            print("  - ìƒì„¸ ì¶”ì  ë¡œê·¸:")
            traceback.print_exc()
            print("=" * 60)
            return None
    
    def download_element_equipment_images(self, char_data):
        """ìºë¦­í„°ì˜ elementì™€ equipment ì´ë¯¸ì§€ë“¤ì„ ë‹¤ìš´ë¡œë“œ"""
        eng_name = char_data.get('english_name', 'Unknown')
        downloaded_files = {'elements': [], 'equipment': []}
        
        # Element ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        for img_data in char_data.get('element_images', []):
            try:
                image_path = self.download_image(
                    img_data['src'], 
                    subfolder="elements_equipment", 
                    eng_name=f"{eng_name}_element_{img_data['alt']}"
                )
                if image_path:
                    downloaded_files['elements'].append(image_path)
            except Exception as e:
                print(f"  âš ï¸ Element ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {img_data['alt']} - {e}")
        
        # Equipment ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ  
        for img_data in char_data.get('equipment_images', []):
            try:
                image_path = self.download_image(
                    img_data['src'], 
                    subfolder="elements_equipment", 
                    eng_name=f"{eng_name}_equipment_{img_data['alt']}"
                )
                if image_path:
                    downloaded_files['equipment'].append(image_path)
            except Exception as e:
                print(f"  âš ï¸ Equipment ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {img_data['alt']} - {e}")
        
        return downloaded_files

# â¬‡ï¸ ì´ ì½”ë“œë¡œ scrape_character_list í•¨ìˆ˜ ì „ì²´ë¥¼ êµì²´í•´ì£¼ì„¸ìš”.

    def scrape_character_list(self):
        """ìºë¦­í„° ëª©ë¡ í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ (ìµœì¢… í•„í„°ë§)"""
        print("ìºë¦­í„° ëª©ë¡ ìŠ¤í¬ë˜í•‘ ì¤‘...")
        try:
            response = requests.get(TARGET_URL, headers=self.headers, timeout=30)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            
            tables = soup.find_all('table', class_='wikitable')
            if not tables:
                print("ìºë¦­í„° í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            characters = []
            for table in tables:
                rows = table.find_all('tr')[1:]  # í—¤ë” ì œì™¸
                
                for row in rows:
                    cols = row.find_all(['td', 'th'])
                    if len(cols) < 2:
                        continue
                    
                    # ìºë¦­í„° ì´ë¦„ì€ ë‘ ë²ˆì§¸ ì—´(cols[1])ì—ì„œ ì¶”ì¶œ
                    name_col = cols[1] if len(cols) > 1 else cols[0]
                    char_link = name_col.find('a')
                    if not char_link:
                        continue

                    # ì´ë¦„ê³¼ URL ì¶”ì¶œ
                    href = char_link.get('href', '')
                    eng_name = char_link.get('title', '').strip()
                    
                    # ë¹„-ìºë¦­í„° í•­ëª© í•„í„°ë§
                    if (not href or not eng_name or
                        href.startswith(('/w/File:', '/w/Category:', '/w/Template:', '/w/Special:')) or
                        eng_name.startswith(('File:', 'Category:', 'Template:'))):
                        continue

                    detail_url = urljoin(BASE_URL, href)
                    
                    # ìºë¦­í„° ì´ë¯¸ì§€ëŠ” ì²« ë²ˆì§¸ ì—´(cols[0])ì—ì„œ ì¶”ì¶œ
                    img_url = ''
                    element_images = []
                    equipment_images = []
                    
                    if len(cols) > 0:
                        # ì²« ë²ˆì§¸ ì—´ì—ì„œ ìºë¦­í„° ì•„ì´ì½˜ ì´ë¯¸ì§€ ì°¾ê¸° (ê°€ì¥ í° ì´ë¯¸ì§€)
                        img_tags = cols[0].find_all('img')
                        for img_tag in img_tags:
                            src = img_tag.get('src', '')
                            alt = img_tag.get('alt', '')
                            # ìºë¦­í„° ì•„ì´ì½˜ì€ ë³´í†µ command.pngë¡œ ëë‚˜ê³  width=80
                            if (src and 'command.png' in alt.lower() and 
                                ('width=80' in src or 'rank5' in src or 's2' in src)):
                                img_url = src
                                break
                        
                        # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                        if img_url and not img_url.startswith('http'):
                            img_url = urljoin(BASE_URL, img_url)
                    
                    # Element & Equipment ì´ë¯¸ì§€ëŠ” ì„¸ ë²ˆì§¸ ì—´(cols[2])ì—ì„œ ì¶”ì¶œ
                    if len(cols) > 2:
                        element_col = cols[2]
                        img_tags = element_col.find_all('img')
                        
                        for img_tag in img_tags:
                            src = img_tag.get('src', '')
                            alt = img_tag.get('alt', '')
                            
                            if src:
                                # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                                if not src.startswith('http'):
                                    src = urljoin(BASE_URL, src)
                                
                                # Element ì´ë¯¸ì§€ (Skill_Type)
                                if 'skill type' in alt.lower() or 'skill_type' in alt.lower():
                                    element_images.append({'src': src, 'alt': alt})
                                # Equipment ì´ë¯¸ì§€ (202*, 216*, Buddy_equipment)
                                elif any(pattern in alt.lower() for pattern in ['icon.png', 'equipment.png']):
                                    equipment_images.append({'src': src, 'alt': alt})
                    
                    characters.append({
                        'english_name': eng_name,
                        'detail_url': detail_url,
                        'image_url': img_url,
                        'korean_name': self.convert_to_korean(eng_name),  # ë¯¸ë¦¬ ë³€í™˜
                        'element_images': element_images,
                        'equipment_images': equipment_images
                    })
            
            print(f"ìºë¦­í„° ëª©ë¡ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: í•„í„°ë§ í›„ {len(characters)}ê°œ")
            return characters
            
        except Exception as e:
            print(f"ìºë¦­í„° ëª©ë¡ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
            return []
        
    def scrape_character_details(self, detail_url, eng_name):
        """ìºë¦­í„° ìƒì„¸ í˜ì´ì§€ ìŠ¤í¬ë˜í•‘"""
        try:
            response = requests.get(detail_url, headers=self.headers, timeout=30)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # infoboxì—ì„œ ë°ì´í„° ì¶”ì¶œ
            infobox = soup.find('table', class_='infobox')
            if not infobox:
                return {}
            
            data = {}
            rows = infobox.find_all('tr')
            
            for row in rows:
                header = row.find(['th', 'td'])
                if not header:
                    continue
                
                header_text = header.get_text(strip=True)
                if 'Rarity' in header_text or 'í¬ê·€ë„' in header_text:
                    rarity_cell = row.find_all(['td', 'th'])[-1]
                    data['rarity'] = rarity_cell.get_text(strip=True)
                elif 'Element' in header_text or 'ì†ì„±' in header_text:
                    element_cell = row.find_all(['td', 'th'])[-1]
                    data['elements'] = element_cell.get_text(strip=True)
                elif 'Weapon' in header_text or 'ë¬´ê¸°' in header_text:
                    weapon_cell = row.find_all(['td', 'th'])[-1]
                    data['weapons'] = weapon_cell.get_text(strip=True)
            
            # ê³ í™”ì§ˆ ì´ë¯¸ì§€ ì¶”ì¶œ
            img_tag = infobox.find('img')
            if img_tag:
                img_src = img_tag.get('src', '')
                if img_src.startswith('http'):
                    data['high_res_image_url'] = img_src
                else:
                    data['high_res_image_url'] = urljoin(BASE_URL, img_src)
            
            return data
            
        except Exception as e:
            print(f"{eng_name} ìƒì„¸ í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
            return {}
    
    def scrape_all_personalities(self):
        """ì „ì²´ í¼ìŠ¤ë„ë¦¬í‹° ë°ì´í„° ìŠ¤í¬ë˜í•‘"""
        print("í¼ìŠ¤ë„ë¦¬í‹° ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì¤‘...")
        try:
            response = requests.get(PERSONALITY_URL, headers=self.headers, timeout=30)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # wikitable í´ë˜ìŠ¤ë¥¼ ê°€ì§„ í…Œì´ë¸”ë“¤ ì°¾ê¸°
            tables = soup.find_all('table', class_='wikitable')
            character_personalities = {}
            
            for table in tables:
                rows = table.find_all('tr')[1:]  # í—¤ë” ì œì™¸
                
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    if len(cells) >= 2:
                        # í¼ìŠ¤ë„ë¦¬í‹° ì´ë¦„
                        personality_cell = cells[0]
                        personality_eng = personality_cell.get_text(strip=True)
                        personality_kor = self.personality_mapping.get(personality_eng, personality_eng)
                        
                        # ìºë¦­í„° ëª©ë¡
                        characters_cell = cells[1]
                        character_links = characters_cell.find_all('a')
                        characters_found = []
                        
                        for link in character_links:
                            href = link.get('href', '')
                            if (href.startswith('/w/') and 
                                'Character' not in href and 
                                'Personality' not in href and
                                'Special:' not in href and
                                'Category:' not in href):
                                
                                char_name = link.get_text(strip=True)
                                if char_name and len(char_name) > 1:
                                    characters_found.append(char_name)
                        
                        # ê° ìºë¦­í„°ì— í¼ìŠ¤ë„ë¦¬í‹° ì¶”ê°€
                        for char_name in characters_found:
                            if char_name not in character_personalities:
                                character_personalities[char_name] = []
                            character_personalities[char_name].append(personality_kor)
            
            print(f"í¼ìŠ¤ë„ë¦¬í‹° ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {len(character_personalities)}ëª…")
            return character_personalities
            
        except Exception as e:
            print(f"í¼ìŠ¤ë„ë¦¬í‹° ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
            return {}
    
    def create_excel_with_images(self, characters):
        """ì´ë¯¸ì§€ í¬í•¨ ì—‘ì…€ íŒŒì¼ ìƒì„±"""
        print("ğŸ“Š ì—‘ì…€ íŒŒì¼ ìƒì„± ì¤‘...")
        try:
            wb = Workbook()
            ws = wb.active
            ws.title = "Characters"
            
            # í—¤ë”
            headers = ['English Name', 'Korean Name', 'Rarity', 'Elements', 'Weapons', 'Personalities', 'Image Path']
            ws.append(headers)
            
            # ë°ì´í„° ì¶”ê°€
            for char in characters:
                row = [
                    char.get('english_name', ''),
                    char.get('korean_name', ''),
                    char.get('rarity', ''),
                    char.get('elements', ''),
                    char.get('weapons', ''),
                    char.get('personalities', ''),
                    char.get('image_path', '')
                ]
                ws.append(row)
            
            # ì—´ ë„ˆë¹„ ì¡°ì •
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except Exception:
                        pass
                adjusted_width = min(max_length + 2, 50)
                ws.column_dimensions[column_letter].width = adjusted_width
            
            # íŒŒì¼ ì €ì¥
            excel_path = CSV_DIR / "another_eden_characters_detailed.xlsx"
            wb.save(excel_path)
            print(f"ì—‘ì…€ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {excel_path}")
            return excel_path
            
        except Exception as e:
            print(f"ì—‘ì…€ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def generate_csv_files(self, characters, personality_data):
        """CSV íŒŒì¼ë“¤ ìƒì„±"""
        print("ğŸ“‹ CSV íŒŒì¼ë“¤ ìƒì„± ì¤‘...")
        
        # 1. í€´ì¦ˆìš© ë°ì´í„° (eden_quiz_data.csv)
        quiz_data = []
        for char in characters:
            quiz_data.append({
                'ìºë¦­í„°ëª…': char.get('korean_name', ''),
                'ì˜ë¬¸ëª…': char.get('english_name', ''),
                'ìºë¦­í„°ì•„ì´ì½˜ê²½ë¡œ': char.get('image_path', ''),
                'í¬ê·€ë„': char.get('rarity', ''),
                'ì†ì„±ëª…ë¦¬ìŠ¤íŠ¸': char.get('elements', ''),
                'ë¬´ê¸°ëª…ë¦¬ìŠ¤íŠ¸': char.get('weapons', ''),
                'ì„±ê²©íŠ¹ì„±ë¦¬ìŠ¤íŠ¸': char.get('personalities', '')
            })
        
        quiz_df = pd.DataFrame(quiz_data)
        quiz_csv_path = CSV_DIR / "eden_quiz_data.csv"
        quiz_df.to_csv(quiz_csv_path, index=False, encoding='utf-8-sig')
        print(f"í€´ì¦ˆ ë°ì´í„° ì €ì¥: {quiz_csv_path}")
        
        # 2. ë£°ë ›ìš© ë°ì´í„° (eden_roulette_data.csv)
        roulette_data = []
        for char in characters:
            roulette_data.append({
                'english_name': char.get('english_name', ''),
                'korean_name': char.get('korean_name', ''),
                'image_path': char.get('image_path', ''),
                'rarity': char.get('rarity', ''),
                'elements': char.get('elements', ''),
                'weapons': char.get('weapons', ''),
                'personalities': char.get('personalities', '')
            })
        
        roulette_df = pd.DataFrame(roulette_data)
        roulette_csv_path = CSV_DIR / "eden_roulette_data.csv"
        roulette_df.to_csv(roulette_csv_path, index=False, encoding='utf-8-sig')
        print(f"ë£°ë › ë°ì´í„° ì €ì¥: {roulette_csv_path}")
        
        # 3. í¼ìŠ¤ë„ë¦¬í‹° ë°ì´í„° (character_personalities.csv)
        personality_list = []
        for eng_name, personalities in personality_data.items():
            kor_name = self.name_mapping.get(eng_name.lower(), eng_name)
            personality_list.append({
                'English_Name': eng_name,
                'Korean_Name': kor_name,
                'Personalities_Korean': ', '.join(personalities),
                'Personalities_Count': len(personalities),
                'Personalities_List': '|'.join(personalities)
            })
        
        personality_df = pd.DataFrame(personality_list)
        personality_df.sort_values('Personalities_Count', ascending=False, inplace=True)
        personality_csv_path = CSV_DIR / "character_personalities.csv"
        personality_df.to_csv(personality_csv_path, index=False, encoding='utf-8-sig')
        print(f"í¼ìŠ¤ë„ë¦¬í‹° ë°ì´í„° ì €ì¥: {personality_csv_path}")
        
        return quiz_csv_path, roulette_csv_path, personality_csv_path
    
    def save_progress(self, characters, personality_data, suffix=""):
        """ì§„í–‰ìƒí™© ì €ì¥ (ì¤‘ê°„ ì €ì¥ìš©)"""
        try:
            print(f"  ğŸ“‹ ë°±ì—… CSV íŒŒì¼ ìƒì„± ì¤‘{suffix}...")
            
            # ì²˜ë¦¬ëœ ìºë¦­í„°ë“¤ë§Œ í•„í„°ë§ (korean_nameì´ ìˆëŠ” ê²ƒë“¤)
            processed_chars = [char for char in characters if char.get('korean_name')]
            
            if not processed_chars:
                print("  âš ï¸ ì²˜ë¦¬ëœ ìºë¦­í„°ê°€ ì—†ì–´ ë°±ì—…ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                return
            
            # ë°±ì—… CSV íŒŒì¼ë“¤ ìƒì„±
            quiz_data = []
            for char in processed_chars:
                quiz_data.append({
                    'ìºë¦­í„°ëª…': char.get('korean_name', ''),
                    'ì˜ë¬¸ëª…': char.get('english_name', ''),
                    'ìºë¦­í„°ì•„ì´ì½˜ê²½ë¡œ': char.get('image_path', ''),
                    'í¬ê·€ë„': char.get('rarity', ''),
                    'ì†ì„±ëª…ë¦¬ìŠ¤íŠ¸': char.get('elements', ''),
                    'ë¬´ê¸°ëª…ë¦¬ìŠ¤íŠ¸': char.get('weapons', ''),
                    'ì„±ê²©íŠ¹ì„±ë¦¬ìŠ¤íŠ¸': char.get('personalities', '')
                })
            
            quiz_df = pd.DataFrame(quiz_data)
            backup_path = CSV_DIR / f"eden_quiz_data{suffix}.csv"
            quiz_df.to_csv(backup_path, index=False, encoding='utf-8-sig')
            print(f"  âœ“ ë°±ì—… ì €ì¥ë¨: {backup_path}")
            
        except Exception as e:
            print(f"  âš ï¸ ë°±ì—… ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def run_full_scraping(self, test_mode=False):
        """ì „ì²´ ìŠ¤í¬ë˜í•‘ ì‹¤í–‰"""
        print("Another Eden í†µí•© ìŠ¤í¬ë˜í¼ ì‹œì‘")
        print("=" * 60)
        
        # SSL ì¸ì¦ì„œ ê²€ì¦ í™œì„±í™”
        print("ğŸ”’ SSL/TLS ì¸ì¦ì„œ ê²€ì¦ì´ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        
        # ë§¤í•‘ ë¡œë“œ
        self.load_name_mapping()
        self.load_personality_mapping()
        
        # 1. ìºë¦­í„° ëª©ë¡ ìŠ¤í¬ë˜í•‘
        characters = self.scrape_character_list()
        if not characters:
            print("ìºë¦­í„° ë°ì´í„° ì—†ìŒ")
            return False
        
        # í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì²˜ìŒ 10ê°œë§Œ ì²˜ë¦¬
        if test_mode:
            characters = characters[:10]
            print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {len(characters)}ê°œ ìºë¦­í„°ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        
        # 2. í¼ìŠ¤ë„ë¦¬í‹° ë°ì´í„° ìŠ¤í¬ë˜í•‘
        personality_data = self.scrape_all_personalities()
        
        # 3. ê° ìºë¦­í„° ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘
        print("ìºë¦­í„° ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ ì¤‘...")
        processed_count = 0
        downloaded_count = 0
        skipped_count = 0
        
        try:
            for i, char in enumerate(characters, 1):
                eng_name = char['english_name']
                print(f"[{i}/{len(characters)}] {eng_name} ì²˜ë¦¬ ì¤‘...")
                
                try:
                    # í•œê¸€ëª…ì€ ì´ë¯¸ ëª©ë¡ì—ì„œ ë³€í™˜ë¨
                    if 'korean_name' not in char:
                        char['korean_name'] = self.convert_to_korean(eng_name)
                    
                    # í¼ìŠ¤ë„ë¦¬í‹° ì •ë³´ (ê°€ì¥ ë¨¼ì € ì²˜ë¦¬)
                    personalities = personality_data.get(eng_name, [])
                    char['personalities'] = ', '.join(personalities)
                    
                    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ë©”ì¸ ë¦¬ìŠ¤íŠ¸ì—ì„œ ê°€ì ¸ì˜¨ URL ì‚¬ìš©)
                    image_url = char.get('image_url', '')
                    image_path = ''
                    
                    if image_url:
                        image_path = self.download_image(image_url, subfolder="", eng_name=eng_name)
                        if image_path:
                            # ìŠ¤í‚µëœ ê²ƒì¸ì§€ ìƒˆë¡œ ë‹¤ìš´ë¡œë“œëœ ê²ƒì¸ì§€ëŠ” download_imageì—ì„œ ì¶œë ¥ë¨
                            if "ìŠ¤í‚µ" in str(image_path) or os.path.exists(PROJECT_ROOT / image_path):
                                downloaded_count += 1  # ê¸°ì¡´ íŒŒì¼ì´ë“  ìƒˆ íŒŒì¼ì´ë“  ì„±ê³µ
                        else:
                            print(f"  âš ï¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {eng_name}")
                    else:
                        print(f"  âŒ ì´ë¯¸ì§€ URL ì—†ìŒ: {eng_name}")
                    
                    char['image_path'] = image_path or ''
                    
                    # Element & Equipment ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                    element_equipment_files = self.download_element_equipment_images(char)
                    element_count = len(element_equipment_files['elements'])
                    equipment_count = len(element_equipment_files['equipment'])
                    
                    if element_count > 0 or equipment_count > 0:
                        print(f"  ğŸ“¦ Element/Equipment: {element_count}ê°œ ì†ì„±, {equipment_count}ê°œ ì¥ë¹„ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ")
                    
                    # ìƒì„¸ ì •ë³´ëŠ” í•„ìš”ì‹œì—ë§Œ (í¬ê·€ë„, ì†ì„±, ë¬´ê¸°ê°€ ì¤‘ìš”í•œ ê²½ìš°ë§Œ)
                    # í˜„ì¬ëŠ” í¼ìŠ¤ë„ë¦¬í‹°ë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ ìƒì„¸ í˜ì´ì§€ ì ‘ê·¼ ìƒëµ
                    char['rarity'] = ''  # í•„ìš”ì‹œ ìƒì„¸ í˜ì´ì§€ì—ì„œ ê°€ì ¸ì˜¤ê¸°
                    char['elements'] = ''
                    char['weapons'] = ''
                    
                    processed_count += 1
                    
                    # ë§¤ 50ê°œë§ˆë‹¤ ì¤‘ê°„ ì €ì¥
                    if processed_count % 50 == 0:
                        print(f"\nğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘... ({processed_count}ê°œ ì²˜ë¦¬ë¨)")
                        self.save_progress(characters[:i], personality_data, suffix=f"_backup_{processed_count}")
                    
                    time.sleep(0.5)  # ì„œë²„ ë¶€í•˜ ë°©ì§€
                    
                except Exception as e:
                    print(f"âš ï¸ {eng_name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    # ì˜¤ë¥˜ê°€ ìˆì–´ë„ ê¸°ë³¸ê°’ìœ¼ë¡œë¼ë„ ë°ì´í„°ë¥¼ ìœ ì§€
                    char['korean_name'] = self.convert_to_korean(eng_name) if 'korean_name' not in char else char['korean_name']
                    char['rarity'] = char.get('rarity', '')
                    char['elements'] = char.get('elements', '')  
                    char['weapons'] = char.get('weapons', '')
                    char['personalities'] = char.get('personalities', '')
                    char['image_path'] = char.get('image_path', '')
                    continue
                    
        except KeyboardInterrupt:
            print(f"\n\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨! ì§€ê¸ˆê¹Œì§€ ì²˜ë¦¬ëœ {processed_count}ê°œ ìºë¦­í„° ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤...")
            # ì¤‘ë‹¨ë˜ì–´ë„ ì§€ê¸ˆê¹Œì§€ì˜ ë°ì´í„°ëŠ” ì €ì¥
            excel_path = self.create_excel_with_images(characters)
            csv_paths = self.generate_csv_files(characters, personality_data)
            
            print(f"\nâœ… ì¤‘ë‹¨ ì‹œì  ë°ì´í„° ì €ì¥ ì™„ë£Œ!")
            print(f"ì²˜ë¦¬ëœ ìºë¦­í„°: {processed_count}/{len(characters)}")
            if excel_path:
                print(f"ì—‘ì…€ íŒŒì¼: {excel_path}")
            if csv_paths:
                for csv_path in csv_paths:
                    if os.path.exists(csv_path):
                        print(f"  âœ“ {csv_path}")
            return True
        
        # 4. ì—‘ì…€ ë° CSV íŒŒì¼ ìƒì„±
        excel_path = self.create_excel_with_images(characters)
        csv_paths = self.generate_csv_files(characters, personality_data)
        
        print("\ní†µí•© ìŠ¤í¬ë˜í•‘ ì™„ë£Œ!")
        print("=" * 60)
        print(f"ì´ ìºë¦­í„° ìˆ˜: {len(characters)}")
        print(f"ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ ìºë¦­í„°: {processed_count}")
        print(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì„±ê³µ: {downloaded_count}/{len(characters)} ({downloaded_count/len(characters)*100:.1f}%)")
        if excel_path:
            print(f"ì—‘ì…€ íŒŒì¼: {excel_path}")
        if csv_paths:
            print(f"CSV íŒŒì¼ë“¤:")
            for csv_path in csv_paths:
                if os.path.exists(csv_path):
                    print(f"  âœ“ {csv_path}")
                else:
                    print(f"  âœ— {csv_path} (ìƒì„± ì‹¤íŒ¨)")
        
        return True


def main(test_mode=False):
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    scraper = MasterScraper()
    success = scraper.run_full_scraping(test_mode=test_mode)
    return success


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
