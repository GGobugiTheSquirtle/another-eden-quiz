## Project: Another Eden Character Data Scraper and Processor

This project is designed to scrape character data from the Another Eden Wiki, process it, and prepare it for use in a Streamlit application.

### Core Components:

1.  **Scraper (`eden_data_preprocess_gui_with_personality.py`):**
    *   A Python script with a Tkinter GUI.
    *   Scrapes the main character list from `https://anothereden.wiki/w/Characters`.
    *   For each character, it navigates to their individual page to scrape detailed information.
    *   Extracts data points like:
        *   Character Icon (image and filename)
        *   Name & Rarity
        *   **Personalities**
        *   Element & Equipment Icons
        *   Release Date
    *   Downloads associated images into the `character_art` directory.
    *   Saves the compiled data into `another_eden_characters_detailed.xlsx`.

2.  **Data Files:**
    *   `another_eden_characters_detailed.xlsx`: The primary output of the scraper, containing the raw, detailed character data.
    *   `Matching_names.csv`: A mapping file to translate English character names to Korean.
    *   `eden_roulette_data.csv`: The final processed CSV file, ready to be used by the Streamlit application.

3.  **Streamlit App (`streamlit_eden_restructure.py`):**
    *   Reads the data from the Excel file generated by the scraper.
    *   Cleans the data (e.g., filters out "Buddy" characters).
    *   Uses `Matching_names.csv` to translate character names into Korean.
    *   Processes and structures the data into the final `eden_roulette_data.csv`.
    *   (Presumably) hosts a web-based tool, likely a character roulette or quiz.

### Workflow:

1.  Run the `eden_data_preprocess_gui_with_personality.py` script.
2.  Use the GUI to start the scraping process.
3.  The script generates `another_eden_characters_detailed.xlsx` and downloads images.
4.  Run the `streamlit_eden_restructure.py` script.
5.  The Streamlit app processes the Excel file and `Matching_names.csv` to create the final `eden_roulette_data.csv`.

### Key Goal from `plan.md`:

A primary objective was to enhance the scraper to extract the "Personalities" for each character from their individual wiki pages and include this information in the final Excel file, a task that has been implemented in the current version of the scraper script.
