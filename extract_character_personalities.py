#!/usr/bin/env python3
"""
ìºë¦­í„°ë³„ í¼ìŠ¤ë„ë¦¬í‹° ë°ì´í„° ì¶”ì¶œ
Characters/Personality í˜ì´ì§€ì—ì„œ ì‹¤ì œ ìºë¦­í„°-í¼ìŠ¤ë„ë¦¬í‹° ë§¤í•‘ ë°ì´í„° ìˆ˜ì§‘
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import os
import re

# ê¸°ë³¸ ì„¤ì •
BASE_URL = "https://anothereden.wiki"
PERSONALITY_URL = "https://anothereden.wiki/w/Characters/Personality"
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))

def load_personality_mapping():
    """í¼ìŠ¤ë„ë¦¬í‹° ë§¤ì¹­ CSV íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    personality_mapping = {}
    try:
        personality_csv_path = os.path.join(SCRIPT_DIR, "personality_matching.csv")
        if os.path.exists(personality_csv_path):
            df = pd.read_csv(personality_csv_path)
            for _, row in df.iterrows():
                if 'English' in row and 'Korean' in row:
                    personality_mapping[row['English']] = row['Korean']
        print(f"âœ… í¼ìŠ¤ë„ë¦¬í‹° ë§¤í•‘ ë¡œë“œ: {len(personality_mapping)}ê°œ")
    except Exception as e:
        print(f"âŒ í¼ìŠ¤ë„ë¦¬í‹° ë§¤í•‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return personality_mapping

def load_character_name_mapping():
    """ìºë¦­í„°ëª… ë§¤ì¹­ CSV íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    name_mapping = {}
    try:
        matching_csv_path = os.path.join(SCRIPT_DIR, "Matching_names.csv")
        if os.path.exists(matching_csv_path):
            df = pd.read_csv(matching_csv_path, encoding='utf-8-sig')
            for _, row in df.iterrows():
                if len(row) >= 2:
                    eng_name = row.iloc[0]  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ (ì˜ì–´ëª…)
                    kor_name = row.iloc[1]  # ë‘ ë²ˆì§¸ ì»¬ëŸ¼ (í•œêµ­ì–´ëª…)
                    if pd.notna(eng_name) and pd.notna(kor_name):
                        name_mapping[eng_name] = kor_name
        print(f"âœ… ìºë¦­í„°ëª… ë§¤í•‘ ë¡œë“œ: {len(name_mapping)}ê°œ")
    except Exception as e:
        print(f"âŒ ìºë¦­í„°ëª… ë§¤í•‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return name_mapping

def extract_character_personalities():
    """Characters/Personality í˜ì´ì§€ì—ì„œ ìºë¦­í„°ë³„ í¼ìŠ¤ë„ë¦¬í‹° ë°ì´í„° ì¶”ì¶œ"""
    print("ğŸ” ìºë¦­í„°ë³„ í¼ìŠ¤ë„ë¦¬í‹° ë°ì´í„° ì¶”ì¶œ ì‹œì‘...")
    
    personality_mapping = load_personality_mapping()
    character_name_mapping = load_character_name_mapping()
    character_personalities = {}
    
    headers_ua = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    try:
        print(f"ğŸ“¡ í˜ì´ì§€ ìš”ì²­: {PERSONALITY_URL}")
        response = requests.get(PERSONALITY_URL, headers=headers_ua, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # wikitable í´ë˜ìŠ¤ë¥¼ ê°€ì§„ í…Œì´ë¸”ë“¤ ì°¾ê¸°
        tables = soup.find_all('table', class_='wikitable')
        print(f"ğŸ“Š ë°œê²¬ëœ í…Œì´ë¸” ìˆ˜: {len(tables)}")
        
        personality_count = 0
        character_total = 0
        
        for table_idx, table in enumerate(tables):
            print(f"\nğŸ” í…Œì´ë¸” {table_idx + 1} ì²˜ë¦¬ ì¤‘...")
            
            rows = table.find_all('tr')[1:]  # í—¤ë” ì œì™¸
            
            for row in rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 2:
                    # ì²« ë²ˆì§¸ ì…€: í¼ìŠ¤ë„ë¦¬í‹° ì´ë¦„
                    personality_cell = cells[0]
                    personality_eng = personality_cell.get_text(strip=True)
                    
                    # í•œêµ­ì–´ í¼ìŠ¤ë„ë¦¬í‹°ëª…ìœ¼ë¡œ ë³€í™˜
                    personality_kor = personality_mapping.get(personality_eng, personality_eng)
                    
                    # ë‘ ë²ˆì§¸ ì…€: ìºë¦­í„° ëª©ë¡
                    characters_cell = cells[1]
                    
                    # ìºë¦­í„° ë§í¬ë“¤ ì¶”ì¶œ
                    character_links = characters_cell.find_all('a', href=True)
                    characters_found = []
                    
                    for link in character_links:
                        href = link.get('href', '')
                        # ìºë¦­í„° í˜ì´ì§€ì¸ì§€ í™•ì¸ (/w/ë¡œ ì‹œì‘í•˜ê³  íŠ¹ì • íŒ¨í„´ ì œì™¸)
                        if (href.startswith('/w/') and 
                            'Character' not in href and 
                            'Personality' not in href and
                            'Special:' not in href and
                            'Category:' not in href):
                            
                            char_name = link.get_text(strip=True)
                            if char_name and len(char_name) > 1:
                                characters_found.append(char_name)
                    
                    if characters_found:
                        personality_count += 1
                        character_total += len(characters_found)
                        
                        print(f"  ğŸ­ {personality_kor} ({personality_eng}): {len(characters_found)}ëª…")
                        
                        # ê° ìºë¦­í„°ì— í¼ìŠ¤ë„ë¦¬í‹° ì¶”ê°€
                        for char_name in characters_found:
                            if char_name not in character_personalities:
                                character_personalities[char_name] = []
                            character_personalities[char_name].append(personality_kor)
                        
                        # ì²˜ìŒ ëª‡ ê°œë§Œ ìƒì„¸ ì¶œë ¥
                        if personality_count <= 5:
                            sample_chars = characters_found[:5]
                            print(f"     â””â”€ ìƒ˜í”Œ: {', '.join(sample_chars)}")
        
        print(f"\nâœ… ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"ğŸ“Š ì´ í¼ìŠ¤ë„ë¦¬í‹° ìˆ˜: {personality_count}ê°œ")
        print(f"ğŸ­ ì´ ìºë¦­í„° ìˆ˜: {len(character_personalities)}ëª…")
        print(f"ğŸ“ˆ ì´ í¼ìŠ¤ë„ë¦¬í‹° ì—°ê²°: {character_total}ê°œ")
        
        # ê²°ê³¼ ì €ì¥
        if character_personalities:
            # ìºë¦­í„°ë³„ í¼ìŠ¤ë„ë¦¬í‹° ë°ì´í„° ìƒì„±
            character_data = []
            for char_name, personalities in character_personalities.items():
                korean_name = character_name_mapping.get(char_name, char_name)
                character_data.append({
                    'English_Name': char_name,
                    'Korean_Name': korean_name,
                    'Personalities_Korean': ', '.join(personalities),
                    'Personalities_Count': len(personalities),
                    'Personalities_List': '|'.join(personalities)  # êµ¬ë¶„ìë¡œ |ì‚¬ìš©
                })
            
            # ì •ë ¬ (í¼ìŠ¤ë„ë¦¬í‹° ìˆ˜ ê¸°ì¤€)
            character_data.sort(key=lambda x: x['Personalities_Count'], reverse=True)
            
            df = pd.DataFrame(character_data)
            output_file = "character_personalities.csv"
            df.to_csv(output_file, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ ë°ì´í„° ì €ì¥: {output_file}")
            
            # ìƒìœ„ 20ëª… ì¶œë ¥
            print(f"\nğŸ† í¼ìŠ¤ë„ë¦¬í‹°ê°€ ë§ì€ ìºë¦­í„° TOP 20:")
            for i, char in enumerate(character_data[:20]):
                print(f"  {i+1:2d}. {char['Korean_Name']} ({char['English_Name']}): {char['Personalities_Count']}ê°œ")
                print(f"      â””â”€ {char['Personalities_Korean']}")
        
        return character_personalities
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {}

if __name__ == "__main__":
    print("ğŸ® Another Eden ìºë¦­í„°ë³„ í¼ìŠ¤ë„ë¦¬í‹° ì¶”ì¶œ")
    print("=" * 60)
    
    result = extract_character_personalities()
    
    if result:
        print(f"\nğŸ‰ ì„±ê³µ! {len(result)}ëª…ì˜ ìºë¦­í„° í¼ìŠ¤ë„ë¦¬í‹° ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ")
        print(f"ğŸ“‹ character_personalities.csv íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”!")
    else:
        print(f"\nâŒ ì‹¤íŒ¨")